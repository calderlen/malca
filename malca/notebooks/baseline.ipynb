{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch GP Baseline Plots for SkyPatrol LCs\n",
        "\n",
        "This notebook runs `per_camera_gp_baseline` for all `../../data/skypatrol2/*.csv` files using `df_plot.plot_many_lc`. Adjust the hyperparameters below as needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from malca.plot import plot_lc_with_residuals, SKYPATROL_CSV_PATHS\n",
        "from malca.baseline import (\n",
        "    global_mean_baseline,\n",
        "    global_median_baseline,\n",
        "    global_rolling_median_baseline,\n",
        "    global_rolling_mean_baseline,\n",
        "    per_camera_mean_baseline,\n",
        "    per_camera_median_baseline,\n",
        "    per_camera_trend_baseline,\n",
        "    per_camera_gp_baseline,\n",
        "    per_camera_gp_baseline_masked,\n",
        ")\n",
        "\n",
        "# Where to save outputs\n",
        "OUT_DIR = Path(\"../../lc_plots/skypatrol_gp\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# GP hyperparameters (tune as desired)\n",
        "gp_kwargs = {\n",
        "    \"sigma\": 0.08,   # mag amplitude; lower to smooth more\n",
        "    \"rho\": 150.0,    # characteristic timescale (days); higher to smooth more\n",
        "    \"q\": 0.7,        # damping; <1 reduces oscillation\n",
        "    \"jitter\": 0.006, # mag floor; set >= median photometric error\n",
        "}\n",
        "\n",
        "# Plot params\n",
        "PLOT_KW = {\n",
        "    \"out_dir\": OUT_DIR,\n",
        "    \"out_format\": \"pdf\",  # change to \"png\" if you prefer\n",
        "    \"show\": False,         # set True to display inline (slower)\n",
        "}\n",
        "\n",
        "print(\"Output directory:\", OUT_DIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch GP baseline plots (SkyPatrol)\n",
        "\n",
        "Use `plot_lc_with_residuals` with `per_camera_gp_baseline` to process all `../../data/skypatrol2/*.csv` files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = plot_lc_with_residuals(\n",
        "    dat_paths=SKYPATROL_CSV_PATHS,\n",
        "    baseline_func=per_camera_gp_baseline,\n",
        "    baseline_kwargs=gp_kwargs,\n",
        "    out_path=OUT_DIR,\n",
        "    out_format=\"pdf\",\n",
        "    show=False,\n",
        ")\n",
        "\n",
        "print(f\"Saved {len(results)} files to {OUT_DIR.resolve()}\")\n",
        "for r in results[:5]:\n",
        "    print(\"-\", r)\n",
        "if len(results) > 5:\n",
        "    print(\"...\", len(results) - 5, \"more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline function smoke tests\n",
        "\n",
        "Quick synthetic checks to ensure each baseline variant returns `baseline`, `resid`, and `sigma_resid` with finite values on a small synthetic dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "N = 40\n",
        "jd = np.arange(N, dtype=float)\n",
        "trend = 0.002 * jd\n",
        "noise = np.random.normal(0, 0.01, N)\n",
        "mag = 15.0 + trend + 0.1 * np.sin(jd / 6.0) + noise\n",
        "err = np.full(N, 0.02, dtype=float)\n",
        "cam = np.where(jd < N / 2, \"A\", \"B\")\n",
        "\n",
        "df_synth = pd.DataFrame(\n",
        "    {\n",
        "        \"JD\": jd,\n",
        "        \"mag\": mag,\n",
        "        \"error\": err,\n",
        "        \"camera#\": cam,\n",
        "    }\n",
        ")\n",
        "\n",
        "def check_baseline_output(df, name):\n",
        "    required = {\"baseline\", \"resid\", \"sigma_resid\"}\n",
        "    assert required.issubset(df.columns), f\"{name}: missing columns\"\n",
        "    finite_baseline = np.isfinite(df[\"baseline\"])\n",
        "    finite_resid = np.isfinite(df[\"resid\"])\n",
        "    finite_sigma = np.isfinite(df[\"sigma_resid\"])\n",
        "    assert finite_baseline.any(), f\"{name}: baseline all-NaN\"\n",
        "    assert finite_resid.any(), f\"{name}: resid all-NaN\"\n",
        "    assert finite_sigma.any(), f\"{name}: sigma_resid all-NaN\"\n",
        "    print(f\"{name}: ok ({finite_baseline.sum()} finite baselines)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from malca.baseline import (\n",
        "    global_mean_baseline,\n",
        "    global_median_baseline,\n",
        "    global_rolling_median_baseline,\n",
        "    global_rolling_mean_baseline,\n",
        "    per_camera_mean_baseline,\n",
        "    per_camera_median_baseline,\n",
        "    per_camera_trend_baseline,\n",
        "    per_camera_gp_baseline,\n",
        "    per_camera_gp_baseline_masked,\n",
        ")\n",
        "\n",
        "tests = [\n",
        "    (\"global_mean_baseline\", global_mean_baseline, {}),\n",
        "    (\"global_median_baseline\", global_median_baseline, {}),\n",
        "    (\"global_rolling_median_baseline\", global_rolling_median_baseline, {\"days\": 40.0, \"min_points\": 5}),\n",
        "    (\"global_rolling_mean_baseline\", global_rolling_mean_baseline, {\"days\": 20.0, \"min_points\": 5}),\n",
        "    (\"per_camera_mean_baseline\", per_camera_mean_baseline, {}),\n",
        "    (\"per_camera_median_baseline\", per_camera_median_baseline, {\"days\": 40.0, \"min_points\": 5}),\n",
        "    (\n",
        "        \"per_camera_trend_baseline\",\n",
        "        per_camera_trend_baseline,\n",
        "        {\"days_short\": 40.0, \"days_long\": 80.0, \"min_points\": 5, \"last_window_guard\": 10.0},\n",
        "    ),\n",
        "    (\n",
        "        \"per_camera_gp_baseline\",\n",
        "        per_camera_gp_baseline,\n",
        "        {\"sigma\": 0.05, \"rho\": 20.0, \"q\": 0.7, \"jitter\": 0.01},\n",
        "    ),\n",
        "    (\n",
        "        \"per_camera_gp_baseline_masked\",\n",
        "        per_camera_gp_baseline_masked,\n",
        "        {\"a1\": 0.01, \"rho1\": 50.0, \"a2\": 0.005, \"rho2\": 100.0, \"jitter\": 0.01},\n",
        "    ),\n",
        "]\n",
        "\n",
        "for name, func, kwargs in tests:\n",
        "    df_out = func(df_synth, **kwargs)\n",
        "    check_baseline_output(df_out, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "n = len(tests)\n",
        "ncols = 2\n",
        "nrows = (n + ncols - 1) // ncols\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 3.4 * nrows), sharex=True)\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, (name, func, kwargs) in zip(axes, tests):\n",
        "    df_out = func(df_synth, **kwargs)\n",
        "    ax.scatter(df_out[\"JD\"], df_out[\"mag\"], s=14, alpha=0.7, label=\"mag\")\n",
        "    ax.plot(df_out[\"JD\"], df_out[\"baseline\"], color=\"orange\", lw=1.4, label=\"baseline\")\n",
        "    ax.set_title(name)\n",
        "    ax.invert_yaxis()\n",
        "    ax.legend(loc=\"best\", fontsize=8)\n",
        "\n",
        "for ax in axes[n:]:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "fig.supxlabel(\"JD\")\n",
        "fig.supylabel(\"Magnitude\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch baselines on SkyPatrol data\n",
        "\n",
        "Run every baseline function over all `SKYPATROL_CSV_PATHS` and write plots to `../../lc_plots/skypatrol_all_baselines/<baseline_tag>`. Set `show=False` to avoid inline rendering; adjust kwargs if you want to tune smoothing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_runs = [\n",
        "    (\"global_mean\", global_mean_baseline, {}),\n",
        "    (\"global_median\", global_median_baseline, {}),\n",
        "    (\"global_roll_median\", global_rolling_median_baseline, {\"days\": 400.0, \"min_points\": 15}),\n",
        "    (\"global_roll_mean\", global_rolling_mean_baseline, {\"days\": 400.0, \"min_points\": 15}),\n",
        "    (\"per_cam_mean\", per_camera_mean_baseline, {}),\n",
        "    (\"per_cam_median\", per_camera_median_baseline, {\"days\": 400.0, \"min_points\": 15}),\n",
        "    (\n",
        "        \"per_cam_trend\",\n",
        "        per_camera_trend_baseline,\n",
        "        {\"days_short\": 200.0, \"days_long\": 800.0, \"min_points\": 12, \"last_window_guard\": 120.0},\n",
        "    ),\n",
        "    (\n",
        "        \"per_cam_gp\",\n",
        "        per_camera_gp_baseline,\n",
        "        {\"sigma\": 0.08, \"rho\": 150.0, \"q\": 0.7, \"jitter\": 0.006},\n",
        "    ),\n",
        "]\n",
        "\n",
        "OUT_ROOT = Path(\"../../lc_plots/skypatrol_all_baselines\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "results_summary = {}\n",
        "for tag, func, kwargs in baseline_runs:\n",
        "    out_dir = OUT_ROOT / tag\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Running {tag} -> {out_dir} ...\")\n",
        "    files = plot_lc_with_residuals(\n",
        "        dat_paths=SKYPATROL_CSV_PATHS,\n",
        "        baseline_func=func,\n",
        "        baseline_kwargs=kwargs,\n",
        "        out_path=out_dir,\n",
        "        out_format=\"pdf\",\n",
        "        show=False,\n",
        "        baseline_tag=tag,\n",
        "    )\n",
        "    results_summary[tag] = len(files) if files else 0\n",
        "    print(f\"  saved {results_summary[tag]} files\")\n",
        "\n",
        "print(\"Done. Counts per baseline:\")\n",
        "for tag, count in results_summary.items():\n",
        "    print(f\"- {tag}: {count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Masked GP Baseline\n",
        "\n",
        "Runs `per_camera_gp_baseline_masked` which masks out significant dips (thresholded by local MAD) before fitting the GP baseline to ensure the baseline follows the quiescent state rather than the dips."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUT_DIR_MASKED = Path(\"../../lc_plots/skypatrol_gp_masked\")\n",
        "OUT_DIR_MASKED.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Masked GP hyperparameters\n",
        "gp_masked_kwargs = {\n",
        "    \"dip_sigma_thresh\": -2.5,\n",
        "    \"pad_days\": 50.,\n",
        "    \"a1\": 0.02**2,\n",
        "    \"rho1\": 1000.0,\n",
        "    \"a2\": 0.01**2,\n",
        "    \"rho2\": 3000.0,\n",
        "    \"jitter\": 0.1,\n",
        "}\n",
        "\n",
        "print(f\"Running per_camera_gp_baseline_masked ...\")\n",
        "results_masked = plot_lc_with_residuals(\n",
        "    dat_paths=SKYPATROL_CSV_PATHS,\n",
        "    baseline_func=per_camera_gp_baseline_masked,\n",
        "    baseline_kwargs=gp_masked_kwargs,\n",
        "    out_path=OUT_DIR_MASKED,\n",
        "    out_format=\"pdf\",\n",
        "    show=False,\n",
        "    baseline_tag=\"per_cam_gp_masked\"\n",
        ")\n",
        "\n",
        "print(f\"Done. Saved {len(results_masked)} files to {OUT_DIR_MASKED.resolve()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug: Check what the GP masked baseline is actually doing\n",
        "# This shows how many points are masked per light curve and per camera\n",
        "\n",
        "from malca.plot import read_skypatrol_csv\n",
        "import numpy as np\n",
        "\n",
        "def debug_gp_masking(csv_path, gp_kwargs):\n",
        "    \"\"\"Show masking statistics for a single light curve.\"\"\"\n",
        "    df = read_skypatrol_csv(csv_path)\n",
        "    source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Source: {source_id}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    for band, band_name in [(0, \"g-band\"), (1, \"V-band\")]:\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        if df_band.empty:\n",
        "            print(f\"  {band_name}: No data\")\n",
        "            continue\n",
        "            \n",
        "        # Run baseline\n",
        "        result = per_camera_gp_baseline_masked(df_band, **gp_kwargs)\n",
        "        \n",
        "        n_total = len(result)\n",
        "        \n",
        "        # Check masking by looking at residuals relative to median\n",
        "        y = result[\"mag\"].values\n",
        "        y_med = np.nanmedian(y)\n",
        "        r0 = y - y_med\n",
        "        \n",
        "        # Robust scale\n",
        "        r0_finite = r0[np.isfinite(r0)]\n",
        "        mad = 1.4826 * np.nanmedian(np.abs(r0_finite - np.nanmedian(r0_finite)))\n",
        "        e_med = np.nanmedian(result[\"error\"].values)\n",
        "        s0 = np.sqrt(mad**2 + e_med**2)\n",
        "        \n",
        "        sig0 = r0 / s0\n",
        "        n_below_thresh = (sig0 < gp_kwargs[\"dip_sigma_thresh\"]).sum()\n",
        "        \n",
        "        # Check final residuals\n",
        "        resid = result[\"resid\"].values\n",
        "        sigma_resid = result[\"sigma_resid\"].values\n",
        "        \n",
        "        n_significant_dips = (sigma_resid < -3).sum()\n",
        "        max_dip_sigma = np.nanmin(sigma_resid)\n",
        "        max_dip_resid = np.nanmax(resid[np.isfinite(resid)])  # positive resid = dip\n",
        "        \n",
        "        print(f\"\\n  {band_name}:\")\n",
        "        print(f\"    Total points: {n_total}\")\n",
        "        print(f\"    Points flagged as dips (< {gp_kwargs['dip_sigma_thresh']}\u03c3): {n_below_thresh}\")\n",
        "        print(f\"    Points masked (incl. padding): ~{n_below_thresh} + neighbors\")\n",
        "        print(f\"    Final significant dips (< -3\u03c3): {n_significant_dips}\")\n",
        "        print(f\"    Max dip depth: {max_dip_resid:.3f} mag ({max_dip_sigma:.1f}\u03c3)\")\n",
        "        print(f\"    Baseline scatter (MAD): {mad:.4f} mag\")\n",
        "        \n",
        "        # Per-camera breakdown\n",
        "        print(f\"    Per-camera stats:\")\n",
        "        for cam in sorted(result[\"camera#\"].unique()):\n",
        "            cam_data = result[result[\"camera#\"] == cam]\n",
        "            cam_dips = (cam_data[\"sigma_resid\"] < -3).sum()\n",
        "            print(f\"      Camera {cam}: {len(cam_data)} pts, {cam_dips} dips\")\n",
        "\n",
        "# Test on a few interesting sources\n",
        "test_sources = [\n",
        "    \"../../data/skypatrol2/532576686103-light-curves.csv\",  # Big dipper\n",
        "    \"../../data/skypatrol2/68720274411-light-curves.csv\",   # Eclipse binary\n",
        "    \"../../data/skypatrol2/438086977939-light-curves.csv\",  # Single eclipse\n",
        "]\n",
        "\n",
        "print(\"GP Masked Kwargs:\", gp_masked_kwargs)\n",
        "for src in test_sources:\n",
        "    debug_gp_masking(src, gp_masked_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare THREE sets of GP hyperparameters side-by-side\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from malca.plot import read_skypatrol_csv\n",
        "import numpy as np\n",
        "\n",
        "# Single parameter set: -1\u03c3, 100d\n",
        "gp_params = {\n",
        "    \"dip_sigma_thresh\": -1.0,\n",
        "    \"pad_days\": 100.0,\n",
        "    \"a1\": 0.02**2,\n",
        "    \"rho1\": 1000.0,\n",
        "    \"a2\": 0.01**2,\n",
        "    \"rho2\": 3000.0,\n",
        "    \"jitter\": 0.006,\n",
        "}\n",
        "\n",
        "def plot_gp_baseline(csv_path, params):\n",
        "    \"\"\"Plot GP baseline for a single light curve.\"\"\"\n",
        "    df = read_skypatrol_csv(csv_path)\n",
        "    source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharex='col')\n",
        "    fig.suptitle(f\"{source_id} \u2014 GP Baseline (-1\u03c3, 100d)\", fontsize=14)\n",
        "    \n",
        "    for col, (band, band_name) in enumerate([(1, \"V-band\"), (0, \"g-band\")]):\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        if df_band.empty:\n",
        "            for row in range(2):\n",
        "                axes[row, col].text(0.5, 0.5, f\"No {band_name} data\", ha='center', va='center')\n",
        "                axes[row, col].set_title(f\"{band_name}\")\n",
        "            continue\n",
        "        \n",
        "        result = per_camera_gp_baseline_masked(df_band.copy(), **params)\n",
        "        \n",
        "        jd = result[\"JD\"].values - 2458000\n",
        "        mag = result[\"mag\"].values\n",
        "        \n",
        "        # Plot raw + baseline\n",
        "        ax_top = axes[0, col]\n",
        "        ax_top.scatter(jd, mag, s=8, alpha=0.4, c='gray', label='Data')\n",
        "        ax_top.plot(jd, result[\"baseline\"].values, '-', color='blue', lw=1.5, alpha=0.9, label='Baseline')\n",
        "        ax_top.invert_yaxis()\n",
        "        ax_top.set_ylabel(f\"{band_name} mag\")\n",
        "        ax_top.set_title(f\"{band_name} \u2014 Raw + Baseline\")\n",
        "        ax_top.legend(loc='best', fontsize=8)\n",
        "        ax_top.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot residuals\n",
        "        ax_bot = axes[1, col]\n",
        "        ax_bot.scatter(jd, result[\"resid\"].values, s=8, alpha=0.5, c='blue')\n",
        "        ax_bot.axhline(0, color='k', linestyle='--', alpha=0.5)\n",
        "        ax_bot.axhline(0.3, color='k', linestyle='-', alpha=0.3)\n",
        "        ax_bot.axhline(-0.3, color='k', linestyle='-', alpha=0.3)\n",
        "        ax_bot.invert_yaxis()\n",
        "        ax_bot.set_ylabel(\"Residual\")\n",
        "        ax_bot.set_xlabel(\"JD - 2458000\")\n",
        "        ax_bot.set_title(f\"{band_name} \u2014 Residuals\")\n",
        "        ax_bot.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Print stats\n",
        "        n_dips = (result[\"sigma_resid\"] < -3).sum()\n",
        "        max_dip = np.nanmax(result[\"resid\"].values)\n",
        "        print(f\"{source_id} {band_name}: {n_dips} dips (>3\u03c3), max dip = {max_dip:.3f} mag\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Compare on key sources\n",
        "test_sources = [\n",
        "    \"../../data/skypatrol2/60130040391-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/68720274411-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/120259184943-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/223339338105-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/377957522430-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/438086977939-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/472447294641-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/515396514761-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/532576686103-light-curves.csv\",\n",
        "]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"GP params (-1\u03c3, 100d):\", gp_params)\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for src in test_sources:\n",
        "    plot_gp_baseline(src, gp_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare RealTerm vs SHOTerm kernels\n",
        "import numpy as np\n",
        "from celerite2 import GaussianProcess, terms\n",
        "\n",
        "def gp_baseline_with_kernel(df_band, kernel, dip_sigma_thresh=-1.0, pad_days=100.0, jitter=0.006):\n",
        "    \"\"\"Run GP baseline with a custom kernel.\"\"\"\n",
        "    t_col, mag_col, err_col, cam_col = \"JD\", \"mag\", \"error\", \"camera#\"\n",
        "    \n",
        "    df_out = df_band.copy()\n",
        "    for col in (\"baseline\", \"resid\", \"sigma_resid\"):\n",
        "        if col not in df_out.columns:\n",
        "            df_out[col] = np.nan\n",
        "    \n",
        "    for _, sub in df_out.groupby(cam_col, group_keys=False):\n",
        "        idx = sub.sort_values(t_col).index\n",
        "        t = df_out.loc[idx, t_col].to_numpy(float)\n",
        "        y = df_out.loc[idx, mag_col].to_numpy(float)\n",
        "        yerr = df_out.loc[idx, err_col].to_numpy(float)\n",
        "        \n",
        "        finite = np.isfinite(t) & np.isfinite(y)\n",
        "        y_med = float(np.nanmedian(y[finite]))\n",
        "        r0 = y - y_med\n",
        "        \n",
        "        r0_f = r0[finite]\n",
        "        med_r = float(np.nanmedian(r0_f))\n",
        "        mad_r = 1.4826 * float(np.nanmedian(np.abs(r0_f - med_r)))\n",
        "        e_med = float(np.nanmedian(yerr[finite & np.isfinite(yerr)])) if np.isfinite(yerr).any() else jitter\n",
        "        s0 = float(np.sqrt(max(mad_r, 0.0)**2 + max(e_med, 0.0)**2))\n",
        "        s0 = max(s0, 1e-6)\n",
        "        \n",
        "        sig0 = r0 / s0\n",
        "        dip_flag = finite & np.isfinite(sig0) & (sig0 < dip_sigma_thresh)\n",
        "        \n",
        "        keep = finite.copy()\n",
        "        if dip_flag.any():\n",
        "            t_dip = t[dip_flag]\n",
        "            bad = np.zeros_like(keep, dtype=bool)\n",
        "            for td in t_dip:\n",
        "                bad |= (np.abs(t - td) <= pad_days)\n",
        "            keep &= ~bad\n",
        "        \n",
        "        if keep.sum() < 10:\n",
        "            df_out.loc[idx, \"baseline\"] = y_med\n",
        "            df_out.loc[idx, \"resid\"] = y - y_med\n",
        "            df_out.loc[idx, \"sigma_resid\"] = (y - y_med) / s0\n",
        "            continue\n",
        "        \n",
        "        t_fit, y_fit = t[keep], y[keep]\n",
        "        yerr_fit = yerr[keep]\n",
        "        med = float(np.nanmedian(yerr_fit[np.isfinite(yerr_fit)]))\n",
        "        yerr_fit = np.where(np.isfinite(yerr_fit), yerr_fit, med)\n",
        "        yerr_fit = np.nan_to_num(yerr_fit, nan=jitter)\n",
        "        \n",
        "        y_mean = float(np.mean(y_fit))\n",
        "        y_fit0 = y_fit - y_mean\n",
        "        \n",
        "        try:\n",
        "            gp = GaussianProcess(kernel)\n",
        "            gp.compute(t_fit, diag=yerr_fit**2)\n",
        "            mu, var = gp.predict(y_fit0, t, return_var=True)\n",
        "        except Exception as e:\n",
        "            print(f\"GP failed: {e}\")\n",
        "            df_out.loc[idx, \"baseline\"] = y_med\n",
        "            df_out.loc[idx, \"resid\"] = y - y_med\n",
        "            df_out.loc[idx, \"sigma_resid\"] = (y - y_med) / s0\n",
        "            continue\n",
        "        \n",
        "        baseline = np.asarray(mu, float) + y_mean\n",
        "        resid = y - baseline\n",
        "        var = np.asarray(var, float)\n",
        "        scale = np.sqrt(np.maximum(var, 0.0) + med**2)\n",
        "        scale = np.where(np.isfinite(scale) & (scale > 0), scale, max(med, 1e-6))\n",
        "        \n",
        "        df_out.loc[idx, \"baseline\"] = baseline\n",
        "        df_out.loc[idx, \"resid\"] = resid\n",
        "        df_out.loc[idx, \"sigma_resid\"] = resid / scale\n",
        "    \n",
        "    return df_out\n",
        "\n",
        "def compare_realterm_vs_sho(csv_path, realterm_params, sho_params, mask_params):\n",
        "    \"\"\"Compare RealTerm vs SHOTerm kernels on a single light curve.\"\"\"\n",
        "    df = read_skypatrol_csv(csv_path)\n",
        "    source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "    \n",
        "    # Build kernels\n",
        "    realterm_kernel = (\n",
        "        terms.RealTerm(a=realterm_params[\"a1\"], c=1.0/realterm_params[\"rho1\"]) +\n",
        "        terms.RealTerm(a=realterm_params[\"a2\"], c=1.0/realterm_params[\"rho2\"])\n",
        "    )\n",
        "    \n",
        "    # Use the same SHOTerm parameterization as per_camera_gp_baseline: (sigma, rho, Q)\n",
        "    sho_kernel = terms.SHOTerm(\n",
        "        sigma=sho_params[\"sigma\"],\n",
        "        rho=sho_params[\"rho\"],\n",
        "        Q=sho_params[\"Q\"],\n",
        "    )\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharex='col')\n",
        "    fig.suptitle(f\"{source_id} \u2014 RealTerm vs SHOTerm Comparison\", fontsize=14)\n",
        "    \n",
        "    for col, (band, band_name) in enumerate([(1, \"V-band\"), (0, \"g-band\")]):\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        if df_band.empty:\n",
        "            for row in range(2):\n",
        "                axes[row, col].text(0.5, 0.5, f\"No {band_name} data\", ha='center', va='center')\n",
        "            continue\n",
        "        \n",
        "        # Run both baselines\n",
        "        result_real = gp_baseline_with_kernel(df_band.copy(), realterm_kernel, **mask_params)\n",
        "        result_sho = gp_baseline_with_kernel(df_band.copy(), sho_kernel, **mask_params)\n",
        "        \n",
        "        jd = result_real[\"JD\"].values - 2458000\n",
        "        mag = result_real[\"mag\"].values\n",
        "        \n",
        "        # Plot raw + baselines\n",
        "        ax_top = axes[0, col]\n",
        "        ax_top.scatter(jd, mag, s=8, alpha=0.4, c='gray', label='Data')\n",
        "\n",
        "        # Plot per-camera baselines to avoid artificial \"combs\" from duplicate timestamps\n",
        "        # and to avoid incorrectly connecting baselines across camera groups.\n",
        "        cams_here = sorted(result_real[\"camera#\"].dropna().unique())\n",
        "        for i_cam, cam in enumerate(cams_here):\n",
        "            r_cam = result_real[result_real[\"camera#\"] == cam][[\"JD\", \"baseline\"]].dropna().copy()\n",
        "            s_cam = result_sho[result_sho[\"camera#\"] == cam][[\"JD\", \"baseline\"]].dropna().copy()\n",
        "\n",
        "            if not r_cam.empty:\n",
        "                r_cam[\"JD_plot\"] = r_cam[\"JD\"].values - 2458000\n",
        "                r_cam = r_cam.sort_values(\"JD_plot\")\n",
        "                if r_cam[\"JD_plot\"].duplicated().any():\n",
        "                    r_cam = r_cam.groupby(\"JD_plot\", as_index=False)[\"baseline\"].median()\n",
        "                ax_top.plot(\n",
        "                    r_cam[\"JD_plot\"],\n",
        "                    r_cam[\"baseline\"],\n",
        "                    '-',\n",
        "                    color='blue',\n",
        "                    lw=1.2,\n",
        "                    alpha=0.7,\n",
        "                    label='RealTerm' if i_cam == 0 else None,\n",
        "                )\n",
        "\n",
        "            if not s_cam.empty:\n",
        "                s_cam[\"JD_plot\"] = s_cam[\"JD\"].values - 2458000\n",
        "                s_cam = s_cam.sort_values(\"JD_plot\")\n",
        "                if s_cam[\"JD_plot\"].duplicated().any():\n",
        "                    s_cam = s_cam.groupby(\"JD_plot\", as_index=False)[\"baseline\"].median()\n",
        "                ax_top.plot(\n",
        "                    s_cam[\"JD_plot\"],\n",
        "                    s_cam[\"baseline\"],\n",
        "                    '--',\n",
        "                    color='red',\n",
        "                    lw=1.2,\n",
        "                    alpha=0.7,\n",
        "                    label='SHOTerm' if i_cam == 0 else None,\n",
        "                )\n",
        "\n",
        "        ax_top.invert_yaxis()\n",
        "        ax_top.set_ylabel(f\"{band_name} mag\")\n",
        "        ax_top.set_title(f\"{band_name} \u2014 Raw + Baselines\")\n",
        "        ax_top.legend(loc='best', fontsize=8)\n",
        "        ax_top.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Plot residuals\n",
        "        ax_bot = axes[1, col]\n",
        "        ax_bot.scatter(jd, result_real[\"resid\"].values, s=6, alpha=0.5, c='blue', marker='o', label='RealTerm')\n",
        "        ax_bot.scatter(jd, result_sho[\"resid\"].values, s=6, alpha=0.5, c='red', marker='x', label='SHOTerm')\n",
        "        ax_bot.axhline(0, color='k', linestyle='--', alpha=0.5)\n",
        "        ax_bot.invert_yaxis()\n",
        "        ax_bot.set_ylabel(\"Residual\")\n",
        "        ax_bot.set_xlabel(\"JD - 2458000\")\n",
        "        ax_bot.set_title(f\"{band_name} \u2014 Residuals\")\n",
        "        ax_bot.legend(loc='best', fontsize=8)\n",
        "        ax_bot.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Stats\n",
        "        n_real = (result_real[\"sigma_resid\"] < -3).sum()\n",
        "        n_sho = (result_sho[\"sigma_resid\"] < -3).sum()\n",
        "        print(f\"{source_id} {band_name}: RealTerm {n_real} dips, SHOTerm {n_sho} dips\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Current RealTerm parameters\n",
        "realterm_params = {\n",
        "    \"a1\": 0.02**2,  # 0.0004\n",
        "    \"rho1\": 1000.0,\n",
        "    \"a2\": 0.01**2,  # 0.0001\n",
        "    \"rho2\": 3000.0,\n",
        "}\n",
        "\n",
        "# SHOTerm parameters in the same parameterization as per_camera_gp_baseline\n",
        "# (sigma [mag], rho [days], Q). Pull from gp_kwargs if present so comparisons are consistent.\n",
        "if \"gp_kwargs\" in globals():\n",
        "    sho_params = {\n",
        "        \"sigma\": float(gp_kwargs.get(\"sigma\", 0.08)),\n",
        "        \"rho\": float(gp_kwargs.get(\"rho\", 150.0)),\n",
        "        \"Q\": float(gp_kwargs.get(\"q\", 0.7)),\n",
        "    }\n",
        "else:\n",
        "    sho_params = {\n",
        "        \"sigma\": 0.08,\n",
        "        \"rho\": 150.0,\n",
        "        \"Q\": 0.7,\n",
        "    }\n",
        "\n",
        "# Masking parameters\n",
        "mask_params = {\n",
        "    \"dip_sigma_thresh\": -1.0,\n",
        "    \"pad_days\": 100.0,\n",
        "    \"jitter\": 0.006,\n",
        "}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RealTerm params:\", realterm_params)\n",
        "print(\"SHOTerm params:\", sho_params)\n",
        "print(\"Masking:\", mask_params)\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test on ALL sources\n",
        "for src in test_sources:\n",
        "    compare_realterm_vs_sho(src, realterm_params, sho_params, mask_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare (A) current per-camera GP baseline vs (B) robust past-only trend baseline\n",
        "# Goal: dip detection without future leakage.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from malca.plot import read_skypatrol_csv\n",
        "from malca.baseline import per_camera_gp_baseline, per_camera_trend_baseline\n",
        "\n",
        "\n",
        "def compare_gp_vs_trend(csv_path, gp_kwargs=None, trend_kwargs=None):\n",
        "    gp_kwargs = gp_kwargs or {\"S0\": 0.0005, \"w0\": 0.0031415926535897933, \"q\": 0.7, \"jitter\": 0.006}\n",
        "    trend_kwargs = trend_kwargs or {\n",
        "        \"days_short\": 200.0,\n",
        "        \"days_long\": 800.0,\n",
        "        \"min_points\": 12,\n",
        "        \"last_window_guard\": 120.0,\n",
        "    }\n",
        "\n",
        "    df = read_skypatrol_csv(csv_path)\n",
        "    source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharex=\"col\")\n",
        "    fig.suptitle(f\"{source_id} \u2014 per_camera_gp_baseline (SHO) vs per_camera_trend_baseline (past-only)\", fontsize=13)\n",
        "\n",
        "    for col, (band, band_name) in enumerate([(1, \"V-band\"), (0, \"g-band\")]):\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        if df_band.empty:\n",
        "            for row in range(2):\n",
        "                axes[row, col].text(0.5, 0.5, f\"No {band_name} data\", ha=\"center\", va=\"center\")\n",
        "            continue\n",
        "\n",
        "        res_gp = per_camera_gp_baseline(df_band.copy(), **gp_kwargs)\n",
        "        res_tr = per_camera_trend_baseline(df_band.copy(), **trend_kwargs)\n",
        "\n",
        "        jd = res_gp[\"JD\"].values - 2458000\n",
        "        mag = res_gp[\"mag\"].values\n",
        "\n",
        "        ax_top = axes[0, col]\n",
        "        ax_top.scatter(jd, mag, s=8, alpha=0.35, c=\"gray\", label=\"Data\")\n",
        "\n",
        "        # Plot per-camera baseline segments (sorted, duplicates collapsed) to avoid plot artifacts\n",
        "        cams_here = sorted(res_gp[\"camera#\"].dropna().unique())\n",
        "        for i_cam, cam in enumerate(cams_here):\n",
        "            gp_cam = res_gp[res_gp[\"camera#\"] == cam][[\"JD\", \"baseline\"]].dropna().copy()\n",
        "            tr_cam = res_tr[res_tr[\"camera#\"] == cam][[\"JD\", \"baseline\"]].dropna().copy()\n",
        "\n",
        "            if not gp_cam.empty:\n",
        "                gp_cam[\"JD_plot\"] = gp_cam[\"JD\"].values - 2458000\n",
        "                gp_cam = gp_cam.sort_values(\"JD_plot\")\n",
        "                if gp_cam[\"JD_plot\"].duplicated().any():\n",
        "                    gp_cam = gp_cam.groupby(\"JD_plot\", as_index=False)[\"baseline\"].median()\n",
        "                ax_top.plot(\n",
        "                    gp_cam[\"JD_plot\"],\n",
        "                    gp_cam[\"baseline\"],\n",
        "                    color=\"tab:blue\",\n",
        "                    lw=1.1,\n",
        "                    alpha=0.75,\n",
        "                    label=\"GP (SHO)\" if i_cam == 0 else None,\n",
        "                )\n",
        "\n",
        "            if not tr_cam.empty:\n",
        "                tr_cam[\"JD_plot\"] = tr_cam[\"JD\"].values - 2458000\n",
        "                tr_cam = tr_cam.sort_values(\"JD_plot\")\n",
        "                if tr_cam[\"JD_plot\"].duplicated().any():\n",
        "                    tr_cam = tr_cam.groupby(\"JD_plot\", as_index=False)[\"baseline\"].median()\n",
        "                ax_top.plot(\n",
        "                    tr_cam[\"JD_plot\"],\n",
        "                    tr_cam[\"baseline\"],\n",
        "                    color=\"tab:orange\",\n",
        "                    lw=1.2,\n",
        "                    alpha=0.8,\n",
        "                    label=\"Trend (past-only)\" if i_cam == 0 else None,\n",
        "                )\n",
        "\n",
        "        ax_top.invert_yaxis()\n",
        "        ax_top.set_ylabel(f\"{band_name} mag\")\n",
        "        ax_top.set_title(f\"{band_name} \u2014 Raw + Baselines\")\n",
        "        ax_top.grid(True, alpha=0.3)\n",
        "        ax_top.legend(loc=\"best\", fontsize=8)\n",
        "\n",
        "        ax_bot = axes[1, col]\n",
        "        ax_bot.scatter(jd, res_gp[\"resid\"].values, s=6, alpha=0.45, c=\"tab:blue\", marker=\"o\", label=\"GP (SHO)\")\n",
        "        ax_bot.scatter(jd, res_tr[\"resid\"].values, s=6, alpha=0.45, c=\"tab:orange\", marker=\"x\", label=\"Trend\")\n",
        "        ax_bot.axhline(0, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
        "        ax_bot.invert_yaxis()\n",
        "        ax_bot.set_ylabel(\"Residual\")\n",
        "        ax_bot.set_xlabel(\"JD - 2458000\")\n",
        "        ax_bot.set_title(f\"{band_name} \u2014 Residuals\")\n",
        "        ax_bot.grid(True, alpha=0.3)\n",
        "        ax_bot.legend(loc=\"best\", fontsize=8)\n",
        "\n",
        "        n_gp = int((res_gp[\"sigma_resid\"] < -3).sum())\n",
        "        n_tr = int((res_tr[\"sigma_resid\"] < -3).sum())\n",
        "        print(f\"{source_id} {band_name}: GP(SHO) {n_gp} dips, Trend {n_tr} dips\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Run on the same sources as above\n",
        "# GP Kwargs 1 - do work: Using S0, w0, Q parameterization\n",
        "_gp_kwargs = {\n",
        "    \"S0\": 0.0005,\n",
        "    \"w0\": 0.0031415926535897933,\n",
        "    \"q\": 0.7,\n",
        "    \"jitter\": 0.006,\n",
        "}\n",
        "_trend_kwargs = {\n",
        "    \"days_short\": 200.0,\n",
        "    \"days_long\": 800.0,\n",
        "    \"min_points\": 12,\n",
        "    \"last_window_guard\": 120.0,\n",
        "}\n",
        "\n",
        "print(\"GP kwargs:\", _gp_kwargs)\n",
        "print(\"Trend kwargs:\", _trend_kwargs)\n",
        "\n",
        "for src in test_sources:\n",
        "    compare_gp_vs_trend(src, gp_kwargs=_gp_kwargs, trend_kwargs=_trend_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare current SHO GP kernel vs a non-oscillatory red-noise GP (OU mixture)\n",
        "# Recommendation for dip baselines: prefer OU-mixture (RealTerm + RealTerm) over SHO if you don't need quasi-periodicity.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from celerite2 import terms\n",
        "from malca.plot import read_skypatrol_csv\n",
        "\n",
        "\n",
        "def compare_sho_vs_ou(csv_path, sho_params=None, ou_params=None, mask_params=None):\n",
        "    sho_params = sho_params or {\"S0\": 0.0005, \"w0\": 0.0031415926535897933, \"Q\": 0.7}\n",
        "\n",
        "    # Two-timescale OU mixture: fast + slow red noise\n",
        "    # Using fixed values that match the RealTerm params from GP Kwargs 1\n",
        "    ou_params = ou_params or {\n",
        "        \"a_fast\": 0.0004,  # a1\n",
        "        \"rho_fast\": 1000.0,  # rho1\n",
        "        \"a_slow\": 0.0001,  # a2\n",
        "        \"rho_slow\": 3000.0,  # rho2\n",
        "    }\n",
        "\n",
        "    mask_params = mask_params or {\"dip_sigma_thresh\": -1.0, \"pad_days\": 100.0, \"jitter\": 0.006}\n",
        "\n",
        "    df = read_skypatrol_csv(csv_path)\n",
        "    source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "\n",
        "    # Build SHO kernel using S0, w0, Q parameterization\n",
        "    if \"S0\" in sho_params and \"w0\" in sho_params:\n",
        "        sho_kernel = terms.SHOTerm(S0=sho_params[\"S0\"], w0=sho_params[\"w0\"], Q=sho_params[\"Q\"])\n",
        "    else:\n",
        "        # Fallback to sigma, rho for backward compatibility\n",
        "        sho_kernel = terms.SHOTerm(sigma=sho_params[\"sigma\"], rho=sho_params[\"rho\"], Q=sho_params[\"Q\"])\n",
        "    ou_kernel = (\n",
        "        terms.RealTerm(a=ou_params[\"a_fast\"], c=1.0 / ou_params[\"rho_fast\"]) +\n",
        "        terms.RealTerm(a=ou_params[\"a_slow\"], c=1.0 / ou_params[\"rho_slow\"])\n",
        "    )\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharex='col')\n",
        "    fig.suptitle(f\"{source_id} \u2014 SHOTerm vs OU-mixture (RealTerm+RealTerm)\", fontsize=14)\n",
        "\n",
        "    for col, (band, band_name) in enumerate([(1, \"V-band\"), (0, \"g-band\")]):\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        if df_band.empty:\n",
        "            for row in range(2):\n",
        "                axes[row, col].text(0.5, 0.5, f\"No {band_name} data\", ha='center', va='center')\n",
        "            continue\n",
        "\n",
        "        res_sho = gp_baseline_with_kernel(df_band.copy(), sho_kernel, **mask_params)\n",
        "        res_ou = gp_baseline_with_kernel(df_band.copy(), ou_kernel, **mask_params)\n",
        "\n",
        "        jd = res_sho[\"JD\"].values - 2458000\n",
        "        mag = res_sho[\"mag\"].values\n",
        "\n",
        "        ax_top = axes[0, col]\n",
        "        ax_top.scatter(jd, mag, s=8, alpha=0.4, c='gray', label='Data')\n",
        "\n",
        "        # Plot per-camera baselines (sorted, duplicates collapsed)\n",
        "        cams_here = sorted(res_sho[\"camera#\"].dropna().unique())\n",
        "        for i_cam, cam in enumerate(cams_here):\n",
        "            sho_cam = res_sho[res_sho[\"camera#\"] == cam][[\"JD\", \"baseline\"]].dropna().copy()\n",
        "            ou_cam = res_ou[res_ou[\"camera#\"] == cam][[\"JD\", \"baseline\"]].dropna().copy()\n",
        "\n",
        "            if not sho_cam.empty:\n",
        "                sho_cam[\"JD_plot\"] = sho_cam[\"JD\"].values - 2458000\n",
        "                sho_cam = sho_cam.sort_values(\"JD_plot\")\n",
        "                if sho_cam[\"JD_plot\"].duplicated().any():\n",
        "                    sho_cam = sho_cam.groupby(\"JD_plot\", as_index=False)[\"baseline\"].median()\n",
        "                ax_top.plot(\n",
        "                    sho_cam[\"JD_plot\"],\n",
        "                    sho_cam[\"baseline\"],\n",
        "                    '-',\n",
        "                    color='tab:blue',\n",
        "                    lw=1.2,\n",
        "                    alpha=0.75,\n",
        "                    label='SHOTerm' if i_cam == 0 else None,\n",
        "                )\n",
        "\n",
        "            if not ou_cam.empty:\n",
        "                ou_cam[\"JD_plot\"] = ou_cam[\"JD\"].values - 2458000\n",
        "                ou_cam = ou_cam.sort_values(\"JD_plot\")\n",
        "                if ou_cam[\"JD_plot\"].duplicated().any():\n",
        "                    ou_cam = ou_cam.groupby(\"JD_plot\", as_index=False)[\"baseline\"].median()\n",
        "                ax_top.plot(\n",
        "                    ou_cam[\"JD_plot\"],\n",
        "                    ou_cam[\"baseline\"],\n",
        "                    '--',\n",
        "                    color='tab:orange',\n",
        "                    lw=1.2,\n",
        "                    alpha=0.75,\n",
        "                    label='OU-mixture' if i_cam == 0 else None,\n",
        "                )\n",
        "\n",
        "        ax_top.invert_yaxis()\n",
        "        ax_top.set_ylabel(f\"{band_name} mag\")\n",
        "        ax_top.set_title(f\"{band_name} \u2014 Raw + Baselines\")\n",
        "        ax_top.legend(loc='best', fontsize=8)\n",
        "        ax_top.grid(True, alpha=0.3)\n",
        "\n",
        "        ax_bot = axes[1, col]\n",
        "        ax_bot.scatter(jd, res_sho[\"resid\"].values, s=6, alpha=0.5, c='tab:blue', marker='o', label='SHOTerm')\n",
        "        ax_bot.scatter(jd, res_ou[\"resid\"].values, s=6, alpha=0.5, c='tab:orange', marker='x', label='OU-mixture')\n",
        "        ax_bot.axhline(0, color='k', linestyle='--', alpha=0.5)\n",
        "        ax_bot.invert_yaxis()\n",
        "        ax_bot.set_ylabel(\"Residual\")\n",
        "        ax_bot.set_xlabel(\"JD - 2458000\")\n",
        "        ax_bot.set_title(f\"{band_name} \u2014 Residuals\")\n",
        "        ax_bot.legend(loc='best', fontsize=8)\n",
        "        ax_bot.grid(True, alpha=0.3)\n",
        "\n",
        "        n_sho = int((res_sho[\"sigma_resid\"] < -3).sum())\n",
        "        n_ou = int((res_ou[\"sigma_resid\"] < -3).sum())\n",
        "        print(f\"{source_id} {band_name}: SHOTerm {n_sho} dips, OU-mixture {n_ou} dips\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Run on the same sources as above\n",
        "# GP Kwargs 1 - do work: Using S0, w0, Q parameterization\n",
        "_sho_params = {\"S0\": 0.0005, \"w0\": 0.0031415926535897933, \"Q\": 0.7}\n",
        "if \"gp_kwargs\" in globals():\n",
        "    # Map your per_camera_gp_baseline params -> SHO kernel params\n",
        "    if \"S0\" in gp_kwargs and \"w0\" in gp_kwargs:\n",
        "        _sho_params = {\n",
        "            \"S0\": float(gp_kwargs.get(\"S0\", _sho_params[\"S0\"])),\n",
        "            \"w0\": float(gp_kwargs.get(\"w0\", _sho_params[\"w0\"])),\n",
        "            \"Q\": float(gp_kwargs.get(\"q\", _sho_params[\"Q\"])),\n",
        "        }\n",
        "    else:\n",
        "        # Fallback: convert sigma, rho to S0, w0 if needed (or use defaults)\n",
        "        _sho_params = {\n",
        "            \"S0\": 0.0005,\n",
        "            \"w0\": 0.0031415926535897933,\n",
        "            \"Q\": float(gp_kwargs.get(\"q\", _sho_params[\"Q\"])),\n",
        "        }\n",
        "\n",
        "_mask_params = {\"dip_sigma_thresh\": -1.0, \"pad_days\": 100.0, \"jitter\": 0.006}\n",
        "\n",
        "print(\"SHO kernel params:\", _sho_params)\n",
        "print(\"Mask params:\", _mask_params)\n",
        "\n",
        "for src in test_sources:\n",
        "    compare_sho_vs_ou(src, sho_params=_sho_params, mask_params=_mask_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# COMPREHENSIVE BASELINE COMPARISON: Test all baseline functions on one light curve\n",
        "# ============================================================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from malca.plot import read_skypatrol_csv\n",
        "from malca.baseline import (\n",
        "    global_mean_baseline,\n",
        "    global_median_baseline,\n",
        "    global_rolling_median_baseline,\n",
        "    global_rolling_mean_baseline,\n",
        "    per_camera_mean_baseline,\n",
        "    per_camera_median_baseline,\n",
        "    per_camera_trend_baseline,\n",
        "    per_camera_gp_baseline,\n",
        "    per_camera_gp_baseline_masked,\n",
        ")\n",
        "\n",
        "def compare_all_baselines(csv_path, gp_kwargs=None, gp_masked_kwargs=None, trend_kwargs=None):\n",
        "    \"\"\"\n",
        "    Compare all baseline functions on a single light curve.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    csv_path : str\n",
        "        Path to SkyPatrol CSV file\n",
        "    gp_kwargs : dict\n",
        "        Parameters for per_camera_gp_baseline\n",
        "    gp_masked_kwargs : dict\n",
        "        Parameters for per_camera_gp_baseline_masked\n",
        "    trend_kwargs : dict\n",
        "        Parameters for per_camera_trend_baseline\n",
        "    \"\"\"\n",
        "    df = read_skypatrol_csv(csv_path)\n",
        "    source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "    \n",
        "    # Use _gp_kwargs (S0, w0, q, jitter) from earlier cells - ENFORCED\n",
        "    if gp_kwargs is None:\n",
        "        if \"_gp_kwargs\" in globals():\n",
        "            gp_kwargs = globals()[\"_gp_kwargs\"].copy()\n",
        "            print(f\"\u2713 Using _gp_kwargs from earlier cell: {gp_kwargs}\")\n",
        "        elif \"gp_kwargs\" in globals():\n",
        "            gp_kwargs = globals()[\"gp_kwargs\"].copy()\n",
        "            print(f\"\u2713 Using gp_kwargs from earlier cell: {gp_kwargs}\")\n",
        "        else:\n",
        "            gp_kwargs = {\"S0\": 0.0005, \"w0\": 0.0031415926535897933, \"q\": 0.7, \"jitter\": 0.006}\n",
        "            print(f\"\u26a0 Using default gp_kwargs: {gp_kwargs}\")\n",
        "    else:\n",
        "        print(f\"\u2713 Using provided gp_kwargs: {gp_kwargs}\")\n",
        "    \n",
        "    # For per_camera_gp_baseline_masked: use _gp_kwargs and convert q->Q, add masking params\n",
        "    if gp_masked_kwargs is None:\n",
        "        if \"_gp_kwargs\" in globals():\n",
        "            # Start with _gp_kwargs and add masking parameters\n",
        "            gp_masked_kwargs = globals()[\"_gp_kwargs\"].copy()\n",
        "            # Convert q to Q (capital) for per_camera_gp_baseline_masked\n",
        "            if \"q\" in gp_masked_kwargs:\n",
        "                gp_masked_kwargs[\"Q\"] = gp_masked_kwargs.pop(\"q\")\n",
        "            # Add masking parameters if not in gp_params\n",
        "            if \"gp_params\" in globals():\n",
        "                gp_params = globals()[\"gp_params\"]\n",
        "                gp_masked_kwargs.setdefault(\"dip_sigma_thresh\", gp_params.get(\"dip_sigma_thresh\", -1.0))\n",
        "                gp_masked_kwargs.setdefault(\"pad_days\", gp_params.get(\"pad_days\", 100.0))\n",
        "            else:\n",
        "                gp_masked_kwargs.setdefault(\"dip_sigma_thresh\", -1.0)\n",
        "                gp_masked_kwargs.setdefault(\"pad_days\", 100.0)\n",
        "            print(f\"\u2713 Using _gp_kwargs + masking params: {gp_masked_kwargs}\")\n",
        "        elif \"gp_params\" in globals():\n",
        "            gp_masked_kwargs = globals()[\"gp_params\"].copy()\n",
        "            print(f\"\u2713 Using gp_params from earlier cell: {gp_masked_kwargs}\")\n",
        "        elif \"gp_masked_kwargs\" in globals():\n",
        "            gp_masked_kwargs = globals()[\"gp_masked_kwargs\"].copy()\n",
        "            print(f\"\u2713 Using gp_masked_kwargs from earlier cell: {gp_masked_kwargs}\")\n",
        "        else:\n",
        "            gp_masked_kwargs = {\n",
        "                \"S0\": 0.0005,\n",
        "                \"w0\": 0.0031415926535897933,\n",
        "                \"Q\": 0.7,\n",
        "                \"dip_sigma_thresh\": -1.0,\n",
        "                \"pad_days\": 100.0,\n",
        "                \"jitter\": 0.006,\n",
        "            }\n",
        "            print(f\"\u26a0 Using default gp_masked_kwargs: {gp_masked_kwargs}\")\n",
        "    else:\n",
        "        print(f\"\u2713 Using provided gp_masked_kwargs: {gp_masked_kwargs}\")\n",
        "    \n",
        "    # Check for trend_kwargs from earlier cells\n",
        "    if trend_kwargs is None:\n",
        "        if \"_trend_kwargs\" in globals():\n",
        "            trend_kwargs = globals()[\"_trend_kwargs\"].copy()\n",
        "            print(f\"\u2713 Using _trend_kwargs from earlier cell: {trend_kwargs}\")\n",
        "        else:\n",
        "            trend_kwargs = {\n",
        "                \"days_short\": 200.0,\n",
        "                \"days_long\": 800.0,\n",
        "                \"min_points\": 12,\n",
        "                \"last_window_guard\": 120.0,\n",
        "            }\n",
        "            print(f\"\u26a0 Using default trend_kwargs: {trend_kwargs}\")\n",
        "    else:\n",
        "        print(f\"\u2713 Using provided trend_kwargs: {trend_kwargs}\")\n",
        "    \n",
        "    print()  # Blank line for readability\n",
        "    \n",
        "    # Define all baseline functions with their parameters\n",
        "    baseline_configs = [\n",
        "        (\"Global Mean\", global_mean_baseline, {}),\n",
        "        (\"Global Median\", global_median_baseline, {}),\n",
        "        (\"Global Rolling Median\", global_rolling_median_baseline, {\"days\": 1000.0, \"min_points\": 10}),\n",
        "        (\"Global Rolling Mean\", global_rolling_mean_baseline, {\"days\": 1000.0, \"min_points\": 10}),\n",
        "        (\"Per-Camera Mean\", per_camera_mean_baseline, {}),\n",
        "        (\"Per-Camera Median\", per_camera_median_baseline, {}),\n",
        "        (\"Per-Camera Trend\", per_camera_trend_baseline, trend_kwargs),\n",
        "        (\"Per-Camera GP (SHO)\", per_camera_gp_baseline, gp_kwargs),\n",
        "        (\"Per-Camera GP Masked\", per_camera_gp_baseline_masked, gp_masked_kwargs),\n",
        "    ]\n",
        "    \n",
        "    # Run all baselines\n",
        "    results = {}\n",
        "    for name, func, kwargs in baseline_configs:\n",
        "        try:\n",
        "            results[name] = func(df.copy(), **kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0\ufe0f  {name} failed: {e}\")\n",
        "            results[name] = None\n",
        "    \n",
        "    # Create comparison plots for each band\n",
        "    for band, band_name in [(1, \"V-band\"), (0, \"g-band\")]:\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        if df_band.empty:\n",
        "            continue\n",
        "        \n",
        "        # Calculate grid size: 3 columns, 2 rows (baselines + residuals)\n",
        "        n_baselines = len([r for r in results.values() if r is not None])\n",
        "        n_cols = 3\n",
        "        n_rows_baseline = (n_baselines + n_cols - 1) // n_cols\n",
        "        \n",
        "        # Create figure with 2 rows: baselines on top, residuals on bottom\n",
        "        fig, axes = plt.subplots(2 * n_rows_baseline, n_cols, figsize=(15, 6 * n_rows_baseline), sharex='col')\n",
        "        fig.suptitle(f\"{source_id} \u2014 {band_name} Baseline & Residual Comparison (All Methods)\", fontsize=14, y=0.995)\n",
        "        \n",
        "        if 2 * n_rows_baseline == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "        elif n_rows_baseline == 1:\n",
        "            axes = axes.reshape(2, -1)\n",
        "        else:\n",
        "            axes = axes.reshape(2 * n_rows_baseline, n_cols)\n",
        "        \n",
        "        colors = plt.cm.tab10(np.linspace(0, 1, len(baseline_configs)))\n",
        "        \n",
        "        for idx, (name, func, kwargs) in enumerate(baseline_configs):\n",
        "            if results[name] is None:\n",
        "                continue\n",
        "            \n",
        "            # Top row: baselines\n",
        "            ax_top = axes[idx // n_cols, idx % n_cols]\n",
        "            # Bottom row: residuals\n",
        "            ax_bot = axes[n_rows_baseline + idx // n_cols, idx % n_cols]\n",
        "            \n",
        "            result = results[name]\n",
        "            \n",
        "            # Filter to this band\n",
        "            result_band = result[result[\"v_g_band\"] == band].copy()\n",
        "            if result_band.empty:\n",
        "                ax_top.text(0.5, 0.5, f\"{name}\\nNo data\", ha='center', va='center', transform=ax_top.transAxes)\n",
        "                ax_top.set_title(name, fontsize=10)\n",
        "                ax_bot.axis('off')\n",
        "                continue\n",
        "            \n",
        "            jd = result_band[\"JD\"].values - 2458000\n",
        "            mag = result_band[\"mag\"].values\n",
        "            baseline = result_band[\"baseline\"].values\n",
        "            resid = result_band[\"resid\"].values\n",
        "            sigma_resid = result_band[\"sigma_resid\"].values\n",
        "            \n",
        "            # ===== TOP PLOT: Data + Baseline =====\n",
        "            ax_top.scatter(jd, mag, s=4, alpha=0.3, c='gray', label='Data', zorder=1)\n",
        "            \n",
        "            # Plot baseline (per-camera if applicable)\n",
        "            if \"camera#\" in result_band.columns:\n",
        "                cams = sorted(result_band[\"camera#\"].dropna().unique())\n",
        "                for cam in cams:\n",
        "                    cam_mask = result_band[\"camera#\"] == cam\n",
        "                    cam_jd = jd[cam_mask]\n",
        "                    cam_baseline = baseline[cam_mask]\n",
        "                    # Sort for plotting\n",
        "                    sort_idx = np.argsort(cam_jd)\n",
        "                    ax_top.plot(cam_jd[sort_idx], cam_baseline[sort_idx], \n",
        "                               '-', color=colors[idx], lw=1.5, alpha=0.8, zorder=2)\n",
        "            else:\n",
        "                # Global baseline - sort for plotting\n",
        "                sort_idx = np.argsort(jd)\n",
        "                ax_top.plot(jd[sort_idx], baseline[sort_idx], \n",
        "                           '-', color=colors[idx], lw=1.5, alpha=0.8, label='Baseline', zorder=2)\n",
        "            \n",
        "            ax_top.invert_yaxis()\n",
        "            ax_top.set_ylabel(\"mag\", fontsize=9)\n",
        "            ax_top.set_title(f\"{name}\", fontsize=10, fontweight='bold')\n",
        "            ax_top.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add statistics text\n",
        "            n_dips = (sigma_resid < -3).sum()\n",
        "            mad = 1.4826 * np.median(np.abs(resid - np.median(resid)))\n",
        "            max_dip = np.nanmax(resid) if len(resid) > 0 else np.nan\n",
        "            \n",
        "            stats_text = f\"3\u03c3 dips: {n_dips}\\nMAD: {mad:.4f}\\nMax dip: {max_dip:.3f}\"\n",
        "            ax_top.text(0.02, 0.98, stats_text, transform=ax_top.transAxes, \n",
        "                       fontsize=7, verticalalignment='top', \n",
        "                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "            \n",
        "            # ===== BOTTOM PLOT: Residuals =====\n",
        "            ax_bot.scatter(jd, resid, s=4, alpha=0.4, c=colors[idx], zorder=1)\n",
        "            ax_bot.axhline(0, color='k', linestyle='--', alpha=0.5, linewidth=0.8)\n",
        "            ax_bot.axhline(0.3, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
        "            ax_bot.axhline(-0.3, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
        "            ax_bot.invert_yaxis()\n",
        "            ax_bot.set_ylabel(\"Residual\", fontsize=9)\n",
        "            if idx // n_cols == n_rows_baseline - 1:  # Bottom row\n",
        "                ax_bot.set_xlabel(\"JD - 2458000\", fontsize=9)\n",
        "            ax_bot.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Hide unused subplots\n",
        "        for idx in range(len(baseline_configs), n_cols * n_rows_baseline):\n",
        "            axes[idx // n_cols, idx % n_cols].axis('off')\n",
        "            axes[n_rows_baseline + idx // n_cols, idx % n_cols].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print summary statistics\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"{source_id} \u2014 {band_name} Summary Statistics\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"{'Baseline Method':<25} {'3\u03c3 Dips':<10} {'MAD':<10} {'Max Dip':<10} {'Mean Resid':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        for name, func, kwargs in baseline_configs:\n",
        "            if results[name] is None:\n",
        "                continue\n",
        "            result_band = results[name][results[name][\"v_g_band\"] == band].copy()\n",
        "            if result_band.empty:\n",
        "                continue\n",
        "            \n",
        "            resid = result_band[\"resid\"].dropna().values\n",
        "            sigma_resid = result_band[\"sigma_resid\"].dropna().values\n",
        "            \n",
        "            n_dips = (sigma_resid < -3).sum()\n",
        "            mad = 1.4826 * np.median(np.abs(resid - np.median(resid)))\n",
        "            max_dip = np.nanmax(resid) if len(resid) > 0 else np.nan\n",
        "            mean_resid = np.mean(resid) if len(resid) > 0 else np.nan\n",
        "            \n",
        "            print(f\"{name:<25} {n_dips:<10} {mad:<10.4f} {max_dip:<10.3f} {mean_resid:<12.6f}\")\n",
        "        \n",
        "        print(\"=\"*80)\n",
        "\n",
        "# Test on a single light curve (change this path to test different sources)\n",
        "test_lc = \"../../data/skypatrol2/532576686103-light-curves.csv\"  # Big dipper - change this!\n",
        "\n",
        "print(f\"Testing all baseline functions on: {test_lc}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "compare_all_baselines(test_lc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# GRID COMPARISON: All baselines for all test light curves\n",
        "# Rows = light curves, Columns = baseline methods (baseline only, no residuals)\n",
        "# ============================================================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from malca.plot import read_skypatrol_csv\n",
        "from malca.baseline import (\n",
        "    global_mean_baseline,\n",
        "    global_median_baseline,\n",
        "    global_rolling_median_baseline,\n",
        "    global_rolling_mean_baseline,\n",
        "    per_camera_mean_baseline,\n",
        "    per_camera_median_baseline,\n",
        "    per_camera_trend_baseline,\n",
        "    per_camera_gp_baseline,\n",
        "    per_camera_gp_baseline_masked,\n",
        ")\n",
        "\n",
        "# All test light curves used in this notebook\n",
        "test_sources_all = [\n",
        "    \"../../data/skypatrol2/60130040391-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/68720274411-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/120259184943-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/223339338105-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/377957522430-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/438086977939-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/472447294641-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/515396514761-light-curves.csv\",\n",
        "    \"../../data/skypatrol2/532576686103-light-curves.csv\",\n",
        "]\n",
        "\n",
        "def plot_all_baselines_grid(csv_paths, band=0, gp_kwargs=None, gp_masked_kwargs=None, trend_kwargs=None):\n",
        "    \"\"\"\n",
        "    Plot all baseline methods for multiple light curves in a grid.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    csv_paths : list\n",
        "        List of paths to SkyPatrol CSV files\n",
        "    band : int\n",
        "        0 for g-band, 1 for V-band\n",
        "    gp_kwargs : dict\n",
        "        Parameters for per_camera_gp_baseline\n",
        "    gp_masked_kwargs : dict\n",
        "        Parameters for per_camera_gp_baseline_masked\n",
        "    trend_kwargs : dict\n",
        "        Parameters for per_camera_trend_baseline\n",
        "    \"\"\"\n",
        "    band_name = \"g-band\" if band == 0 else \"V-band\"\n",
        "    \n",
        "    # Use _gp_kwargs (S0, w0, q, jitter) from earlier cells - ENFORCED\n",
        "    if gp_kwargs is None:\n",
        "        if \"_gp_kwargs\" in globals():\n",
        "            gp_kwargs = globals()[\"_gp_kwargs\"].copy()\n",
        "        elif \"gp_kwargs\" in globals():\n",
        "            gp_kwargs = globals()[\"gp_kwargs\"].copy()\n",
        "        else:\n",
        "            gp_kwargs = {\"S0\": 0.0005, \"w0\": 0.0031415926535897933, \"q\": 0.7, \"jitter\": 0.006}\n",
        "    \n",
        "    # For per_camera_gp_baseline_masked: use _gp_kwargs and convert q->Q, add masking params\n",
        "    if gp_masked_kwargs is None:\n",
        "        if \"_gp_kwargs\" in globals():\n",
        "            # Start with _gp_kwargs and add masking parameters\n",
        "            gp_masked_kwargs = globals()[\"_gp_kwargs\"].copy()\n",
        "            # Convert q to Q (capital) for per_camera_gp_baseline_masked\n",
        "            if \"q\" in gp_masked_kwargs:\n",
        "                gp_masked_kwargs[\"Q\"] = gp_masked_kwargs.pop(\"q\")\n",
        "            # Add masking parameters if not in gp_params\n",
        "            if \"gp_params\" in globals():\n",
        "                gp_params = globals()[\"gp_params\"]\n",
        "                gp_masked_kwargs.setdefault(\"dip_sigma_thresh\", gp_params.get(\"dip_sigma_thresh\", -1.0))\n",
        "                gp_masked_kwargs.setdefault(\"pad_days\", gp_params.get(\"pad_days\", 100.0))\n",
        "            else:\n",
        "                gp_masked_kwargs.setdefault(\"dip_sigma_thresh\", -1.0)\n",
        "                gp_masked_kwargs.setdefault(\"pad_days\", 100.0)\n",
        "        elif \"gp_params\" in globals():\n",
        "            gp_masked_kwargs = globals()[\"gp_params\"].copy()\n",
        "        elif \"gp_masked_kwargs\" in globals():\n",
        "            gp_masked_kwargs = globals()[\"gp_masked_kwargs\"].copy()\n",
        "        else:\n",
        "            gp_masked_kwargs = {\n",
        "                \"S0\": 0.0005,\n",
        "                \"w0\": 0.0031415926535897933,\n",
        "                \"Q\": 0.7,\n",
        "                \"dip_sigma_thresh\": -1.0,\n",
        "                \"pad_days\": 100.0,\n",
        "                \"jitter\": 0.006,\n",
        "            }\n",
        "    \n",
        "    if trend_kwargs is None:\n",
        "        if \"_trend_kwargs\" in globals():\n",
        "            trend_kwargs = globals()[\"_trend_kwargs\"].copy()\n",
        "        else:\n",
        "            trend_kwargs = {\n",
        "                \"days_short\": 200.0,\n",
        "                \"days_long\": 800.0,\n",
        "                \"min_points\": 12,\n",
        "                \"last_window_guard\": 120.0,\n",
        "            }\n",
        "    \n",
        "    # Define all baseline functions with their parameters\n",
        "    baseline_configs = [\n",
        "        (\"Global Mean\", global_mean_baseline, {}),\n",
        "        (\"Global Median\", global_median_baseline, {}),\n",
        "        (\"Global Rolling Median\", global_rolling_median_baseline, {\"days\": 1000.0, \"min_points\": 10}),\n",
        "        (\"Global Rolling Mean\", global_rolling_mean_baseline, {\"days\": 1000.0, \"min_points\": 10}),\n",
        "        (\"Per-Camera Mean\", per_camera_mean_baseline, {}),\n",
        "        (\"Per-Camera Median\", per_camera_median_baseline, {}),\n",
        "        (\"Per-Camera Trend\", per_camera_trend_baseline, trend_kwargs),\n",
        "        (\"Per-Camera GP (SHO)\", per_camera_gp_baseline, gp_kwargs),\n",
        "        (\"Per-Camera GP Masked\", per_camera_gp_baseline_masked, gp_masked_kwargs),\n",
        "    ]\n",
        "    \n",
        "    n_rows = len(csv_paths)\n",
        "    n_cols = len(baseline_configs)\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 2.5 * n_rows), sharex='col', sharey='row')\n",
        "    fig.suptitle(f\"{band_name} \u2014 All Baselines Comparison (Rows=Light Curves, Cols=Methods)\", fontsize=14, y=0.995)\n",
        "    \n",
        "    if n_rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    if n_cols == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "    \n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(baseline_configs)))\n",
        "    \n",
        "    # Process each light curve\n",
        "    for row_idx, csv_path in enumerate(csv_paths):\n",
        "        df = read_skypatrol_csv(csv_path)\n",
        "        source_id = Path(csv_path).stem.replace(\"-light-curves\", \"\")\n",
        "        df_band = df[df[\"v_g_band\"] == band].copy()\n",
        "        \n",
        "        if df_band.empty:\n",
        "            for col_idx in range(n_cols):\n",
        "                axes[row_idx, col_idx].text(0.5, 0.5, \"No data\", ha='center', va='center', \n",
        "                                           transform=axes[row_idx, col_idx].transAxes)\n",
        "                axes[row_idx, col_idx].set_title(baseline_configs[col_idx][0] if row_idx == 0 else \"\", fontsize=8)\n",
        "            continue\n",
        "        \n",
        "        # Run all baselines for this light curve\n",
        "        results = {}\n",
        "        for name, func, kwargs in baseline_configs:\n",
        "            try:\n",
        "                results[name] = func(df.copy(), **kwargs)\n",
        "            except Exception as e:\n",
        "                results[name] = None\n",
        "        \n",
        "        # Plot each baseline method\n",
        "        for col_idx, (name, func, kwargs) in enumerate(baseline_configs):\n",
        "            ax = axes[row_idx, col_idx]\n",
        "            \n",
        "            if results[name] is None:\n",
        "                ax.text(0.5, 0.5, f\"{name}\\nFailed\", ha='center', va='center', \n",
        "                       transform=ax.transAxes, fontsize=7)\n",
        "                ax.set_title(name if row_idx == 0 else \"\", fontsize=8)\n",
        "                continue\n",
        "            \n",
        "            result_band = results[name][results[name][\"v_g_band\"] == band].copy()\n",
        "            if result_band.empty:\n",
        "                ax.text(0.5, 0.5, \"No data\", ha='center', va='center', \n",
        "                       transform=ax.transAxes, fontsize=7)\n",
        "                ax.set_title(name if row_idx == 0 else \"\", fontsize=8)\n",
        "                continue\n",
        "            \n",
        "            jd = result_band[\"JD\"].values - 2458000\n",
        "            mag = result_band[\"mag\"].values\n",
        "            baseline = result_band[\"baseline\"].values\n",
        "            \n",
        "            # Plot data and baseline\n",
        "            ax.scatter(jd, mag, s=2, alpha=0.2, c='gray', zorder=1)\n",
        "            \n",
        "            # Plot baseline (per-camera if applicable)\n",
        "            if \"camera#\" in result_band.columns:\n",
        "                cams = sorted(result_band[\"camera#\"].dropna().unique())\n",
        "                for cam in cams:\n",
        "                    cam_mask = result_band[\"camera#\"] == cam\n",
        "                    cam_jd = jd[cam_mask]\n",
        "                    cam_baseline = baseline[cam_mask]\n",
        "                    # Sort for plotting\n",
        "                    sort_idx = np.argsort(cam_jd)\n",
        "                    ax.plot(cam_jd[sort_idx], cam_baseline[sort_idx], \n",
        "                           '-', color=colors[col_idx], lw=1.2, alpha=0.8, zorder=2)\n",
        "            else:\n",
        "                # Global baseline - sort for plotting\n",
        "                sort_idx = np.argsort(jd)\n",
        "                ax.plot(jd[sort_idx], baseline[sort_idx], \n",
        "                       '-', color=colors[col_idx], lw=1.2, alpha=0.8, zorder=2)\n",
        "            \n",
        "            ax.invert_yaxis()\n",
        "            \n",
        "            # Labels\n",
        "            if row_idx == 0:\n",
        "                ax.set_title(name, fontsize=8, fontweight='bold')\n",
        "            if col_idx == 0:\n",
        "                ax.set_ylabel(f\"{source_id}\\nmag\", fontsize=7)\n",
        "            if row_idx == n_rows - 1:\n",
        "                ax.set_xlabel(\"JD - 2458000\", fontsize=7)\n",
        "            \n",
        "            ax.grid(True, alpha=0.2)\n",
        "            ax.tick_params(labelsize=6)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save g-band plots to PDF\n",
        "    if band == 0:  # g-band\n",
        "        out_dir = Path(\"../../lc_plots/baseline_comparison_grid\")\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        out_path = out_dir / f\"all_baselines_gband_comparison.pdf\"\n",
        "        fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"\u2713 Saved g-band plot to: {out_path.resolve()}\")\n",
        "    \n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Create output directory\n",
        "out_dir = Path(\"../../lc_plots/baseline_comparison_grid\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output directory: {out_dir.resolve()}\")\n",
        "\n",
        "# Plot for g-band (saved to PDF)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"g-band Baseline Comparison Grid\")\n",
        "print(\"=\"*80)\n",
        "plot_all_baselines_grid(test_sources_all, band=0)\n",
        "\n",
        "# Plot for V-band (display only)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"V-band Baseline Comparison Grid\")\n",
        "print(\"=\"*80)\n",
        "plot_all_baselines_grid(test_sources_all, band=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# INJECTION TESTS: Test GP baseline on synthetic big dippers vs non-dippers\n",
        "# ============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from malca.baseline import per_camera_gp_baseline, per_camera_gp_baseline_masked\n",
        "\n",
        "def generate_synthetic_lc(n_points=500, jd_start=2458000, cadence=1.0, \n",
        "                          baseline_mag=15.0, noise_level=0.01, \n",
        "                          inject_signal=None, cameras=None):\n",
        "    \"\"\"\n",
        "    Generate synthetic light curve with optional injected signal.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_points : int\n",
        "        Number of data points\n",
        "    jd_start : float\n",
        "        Starting JD\n",
        "    cadence : float\n",
        "        Days between observations\n",
        "    baseline_mag : float\n",
        "        Baseline magnitude\n",
        "    noise_level : float\n",
        "        Photometric noise (mag)\n",
        "    inject_signal : callable or None\n",
        "        Function f(jd) that returns magnitude offset to inject\n",
        "    cameras : list or None\n",
        "        List of camera names. If None, uses single camera \"A\"\n",
        "    \"\"\"\n",
        "    jd = jd_start + np.arange(n_points) * cadence\n",
        "    mag = np.full(n_points, baseline_mag, dtype=float)\n",
        "    \n",
        "    # Add injected signal if provided\n",
        "    if inject_signal is not None:\n",
        "        signal = inject_signal(jd)\n",
        "        mag += signal\n",
        "    \n",
        "    # Add noise\n",
        "    noise = np.random.normal(0, noise_level, n_points)\n",
        "    mag += noise\n",
        "    \n",
        "    # Assign cameras\n",
        "    if cameras is None:\n",
        "        cameras = [\"A\"] * n_points\n",
        "    elif len(cameras) == 1:\n",
        "        cameras = cameras * n_points\n",
        "    else:\n",
        "        # Cycle through cameras\n",
        "        cameras = [cameras[i % len(cameras)] for i in range(n_points)]\n",
        "    \n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        \"JD\": jd,\n",
        "        \"mag\": mag,\n",
        "        \"error\": np.full(n_points, noise_level, dtype=float),\n",
        "        \"camera#\": cameras,\n",
        "        \"v_g_band\": [0] * n_points,  # g-band\n",
        "    })\n",
        "    \n",
        "    return df\n",
        "\n",
        "def single_big_dipper_signal(jd, dip_start=None, dip_duration=60.0, depth=0.8, shape=\"gaussian\", quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate single, non-periodic big dipper signal: one deep dip lasting 45+ days.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    jd : array\n",
        "        Julian dates\n",
        "    dip_start : float or None\n",
        "        JD of dip center. If None, places dip after quiescent period.\n",
        "    dip_duration : float\n",
        "        Full width of dip in days (should be >= 45 days for big dippers)\n",
        "    depth : float\n",
        "        Dip depth in magnitudes (positive = fainter)\n",
        "    shape : str\n",
        "        \"gaussian\" for smooth Gaussian dip, \"box\" for flat-bottomed dip\n",
        "    quiescent_duration : float\n",
        "        Duration of quiescent period at the beginning (days)\n",
        "    \"\"\"\n",
        "    if dip_start is None:\n",
        "        # Place dip after quiescent period\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) / 3.0\n",
        "    \n",
        "    # Distance from dip center\n",
        "    dist = np.abs(jd - dip_start)\n",
        "    half_width = dip_duration / 2.0\n",
        "    \n",
        "    if shape == \"gaussian\":\n",
        "        # Smooth Gaussian-like dip\n",
        "        dip = depth * np.exp(-0.5 * (dist / (half_width / 2.0))**2)\n",
        "    elif shape == \"box\":\n",
        "        # Flat-bottomed dip (more realistic for some dippers)\n",
        "        dip = np.where(dist < half_width, depth, 0.0)\n",
        "        # Smooth edges\n",
        "        edge_width = 5.0  # days\n",
        "        edge_mask = (dist >= half_width) & (dist < half_width + edge_width)\n",
        "        dip[edge_mask] = depth * np.exp(-(dist[edge_mask] - half_width) / edge_width)\n",
        "    else:\n",
        "        # Default to Gaussian\n",
        "        dip = depth * np.exp(-0.5 * (dist / (half_width / 2.0))**2)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    dip[quiescent_mask] = 0.0\n",
        "    \n",
        "    return dip\n",
        "\n",
        "def shallow_variability_signal(jd, amplitude=0.05, timescale=20.0, quiescent_duration=500.0):\n",
        "    \"\"\"Shallow, smooth variability (not a dipper).\"\"\"\n",
        "    signal = amplitude * np.sin(2 * np.pi * (jd - jd[0] - quiescent_duration) / timescale)\n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def camera_offset_signal(jd, cameras, offset_magnitude=0.2, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate camera offset pattern: systematic magnitude shifts per camera.\n",
        "    Creates horizontal bands in the light curve.\n",
        "    \"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    unique_cams = sorted(set(cameras))\n",
        "    for i, cam in enumerate(unique_cams):\n",
        "        cam_mask = np.array([c == cam for c in cameras])\n",
        "        # Offset each camera by different amount\n",
        "        signal[cam_mask] = (i - len(unique_cams)/2) * offset_magnitude / len(unique_cams)\n",
        "    \n",
        "    # Ensure quiescent period at beginning (no offsets during quiescence)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def bad_point_cluster_signal(jd, cluster_center=None, cluster_duration=50.0, \n",
        "                              cluster_offset=0.4, cluster_width=20.0, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate bad point cluster: localized cluster of faint points (outliers).\n",
        "    \"\"\"\n",
        "    if cluster_center is None:\n",
        "        cluster_center = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.5\n",
        "    \n",
        "    # Create a cluster of bad points\n",
        "    dist = np.abs(jd - cluster_center)\n",
        "    signal = np.where(dist < cluster_width, cluster_offset, 0.0)\n",
        "    # Add some randomness to make it look like bad measurements\n",
        "    signal = signal * (1.0 + 0.2 * np.random.randn(len(jd)))\n",
        "    signal = np.clip(signal, 0, None)  # Only positive offsets (fainter)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def semi_regular_variable_signal(jd, base_period=100.0, period_variation=0.3, \n",
        "                                  amplitude=0.15, amplitude_variation=0.2, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate semi-regular variable: oscillating with varying period and amplitude.\n",
        "    \"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    t = jd - jd[0] - quiescent_duration  # Start timing after quiescent period\n",
        "    t = np.maximum(t, 0.0)  # Don't go negative\n",
        "    \n",
        "    # Vary period and amplitude over time\n",
        "    for i in range(len(jd)):\n",
        "        if t[i] <= 0:\n",
        "            signal[i] = 0.0\n",
        "        else:\n",
        "            # Period varies around base_period\n",
        "            period = base_period * (1.0 + period_variation * np.sin(2 * np.pi * t[i] / 2000.0))\n",
        "            # Amplitude varies\n",
        "            amp = amplitude * (1.0 + amplitude_variation * np.cos(2 * np.pi * t[i] / 1500.0))\n",
        "            signal[i] = amp * np.sin(2 * np.pi * t[i] / period)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def contact_binary_signal(jd, period=0.5, amplitude=0.3, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate contact binary signal: periodic double-peaked light curve.\n",
        "    Period is in days (typically 0.5 days for contact binaries).\n",
        "    \"\"\"\n",
        "    # Start phase after quiescent period\n",
        "    phase = ((jd - jd[0] - quiescent_duration) % period) / period\n",
        "    # Double-peaked: two minima, two maxima per period\n",
        "    signal = amplitude * (1.0 - np.abs(np.sin(2 * np.pi * phase)))\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def ttauri_like_signal(jd, base_mag=15.0, scatter_amplitude=1.0, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate T Tauri-like signal: large irregular scatter, no clear pattern.\n",
        "    \"\"\"\n",
        "    # Large random variations with some correlation\n",
        "    n = len(jd)\n",
        "    # Create correlated noise\n",
        "    correlation_timescale = 5.0  # days\n",
        "    dt = np.diff(jd)\n",
        "    signal = np.zeros(n)\n",
        "    \n",
        "    # Find start of active period\n",
        "    active_start_idx = np.searchsorted(jd, jd[0] + quiescent_duration)\n",
        "    \n",
        "    if active_start_idx > 0:\n",
        "        signal[active_start_idx] = np.random.randn() * scatter_amplitude\n",
        "    \n",
        "    for i in range(active_start_idx + 1, n):\n",
        "        # Random walk with some correlation\n",
        "        signal[i] = signal[i-1] * np.exp(-dt[i-1] / correlation_timescale) + \\\n",
        "                     np.random.randn() * scatter_amplitude * 0.5\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def rcb_like_signal(jd, n_events=3, event_duration=30.0, event_depth=0.8, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate R Coronae Borealis-like signal: sudden deep dimmings with gradual recovery.\n",
        "    \"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    t_span = jd[-1] - jd[0] - quiescent_duration  # Only place events after quiescent period\n",
        "    \n",
        "    # Place events randomly after quiescent period\n",
        "    event_times = jd[0] + quiescent_duration + np.random.rand(n_events) * t_span\n",
        "    \n",
        "    for event_time in event_times:\n",
        "        dist = jd - event_time\n",
        "        # Deep dimming with gradual recovery\n",
        "        # Fast drop, slow recovery\n",
        "        drop = np.where(dist > 0, \n",
        "                       event_depth * np.exp(-dist / (event_duration * 0.3)),  # Fast drop\n",
        "                       0.0)\n",
        "        recovery = np.where(dist > 0,\n",
        "                           event_depth * np.exp(-dist / (event_duration * 2.0)),  # Slow recovery\n",
        "                           0.0)\n",
        "        signal += np.maximum(drop, recovery)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def deep_complex_dip_signal(jd, dip_start=None, dip_duration=200.0, max_depth=1.5, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate deep, complex dip with multiple minima and structured recovery.\n",
        "    Mimics patterns like J070519+061219 with very deep, complex dips.\n",
        "    \"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.3\n",
        "    \n",
        "    dist = jd - dip_start\n",
        "    half_width = dip_duration / 2.0\n",
        "    \n",
        "    # Main deep dip\n",
        "    main_dip = max_depth * np.exp(-0.5 * (dist / (half_width * 0.4))**2)\n",
        "    \n",
        "    # Add secondary minima (structure within the dip)\n",
        "    secondary1 = 0.3 * max_depth * np.exp(-0.5 * ((dist - half_width * 0.3) / (half_width * 0.2))**2)\n",
        "    secondary2 = 0.2 * max_depth * np.exp(-0.5 * ((dist + half_width * 0.2) / (half_width * 0.15))**2)\n",
        "    \n",
        "    # Asymmetric recovery (faster on one side)\n",
        "    recovery = np.where(dist > half_width,\n",
        "                       0.3 * max_depth * np.exp(-(dist - half_width) / (half_width * 1.5)),\n",
        "                       0.0)\n",
        "    \n",
        "    signal = main_dip + secondary1 + secondary2 + recovery\n",
        "    # Only apply within the dip region\n",
        "    signal = np.where(np.abs(dist) < dip_duration, signal, 0.0)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def broad_u_shaped_dip_signal(jd, dip_start=None, dip_duration=300.0, depth=1.2, shape=\"U\", quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate broad, U/V-shaped dip. Mimics patterns like J081523-385923, J183153-284827.\n",
        "    \"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.2\n",
        "    \n",
        "    dist = jd - dip_start\n",
        "    half_width = dip_duration / 2.0\n",
        "    \n",
        "    if shape == \"U\":\n",
        "        # Broad U-shaped: flat bottom with smooth edges\n",
        "        signal = np.where(np.abs(dist) < half_width * 0.6, depth, 0.0)\n",
        "        # Smooth edges\n",
        "        edge_mask = (np.abs(dist) >= half_width * 0.6) & (np.abs(dist) < half_width)\n",
        "        signal[edge_mask] = depth * np.exp(-((np.abs(dist[edge_mask]) - half_width * 0.6) / (half_width * 0.2))**2)\n",
        "    else:  # V-shaped\n",
        "        # V-shaped: linear decrease to center\n",
        "        signal = np.where(np.abs(dist) < half_width,\n",
        "                         depth * (1.0 - np.abs(dist) / half_width),\n",
        "                         0.0)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def sudden_state_change_signal(jd, change_time=None, depth=0.8, recovery_time=None, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate sudden jump to fainter state with sustained fainter level.\n",
        "    Mimics patterns like J085816-430955.\n",
        "    \"\"\"\n",
        "    if change_time is None:\n",
        "        change_time = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.3\n",
        "    \n",
        "    if recovery_time is None:\n",
        "        recovery_time = jd[-1]  # No recovery, stays faint\n",
        "    \n",
        "    signal = np.zeros_like(jd)\n",
        "    \n",
        "    # Sudden drop at change_time\n",
        "    drop_mask = (jd >= change_time) & (jd < recovery_time)\n",
        "    signal[drop_mask] = depth\n",
        "    \n",
        "    # Gradual recovery if recovery_time is before end\n",
        "    if recovery_time < jd[-1]:\n",
        "        recovery_mask = jd >= recovery_time\n",
        "        recovery_dist = jd[recovery_mask] - recovery_time\n",
        "        recovery_span = jd[-1] - recovery_time\n",
        "        signal[recovery_mask] = depth * (1.0 - recovery_dist / recovery_span)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def multiple_irregular_dips_signal(jd, n_dips=3, base_duration=150.0, base_depth=0.8, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate multiple, somewhat irregular dips. Mimics patterns like J181707-164819.\n",
        "    \"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    t_span = jd[-1] - jd[0] - quiescent_duration\n",
        "    \n",
        "    # Place dips at different times with varying properties (after quiescent period)\n",
        "    dip_times = jd[0] + quiescent_duration + np.linspace(0.1, 0.7, n_dips) * t_span\n",
        "    \n",
        "    for i, dip_time in enumerate(dip_times):\n",
        "        # Vary duration and depth\n",
        "        duration = base_duration * (0.8 + 0.4 * np.random.rand())\n",
        "        depth = base_depth * (0.7 + 0.6 * np.random.rand())\n",
        "        \n",
        "        dist = jd - dip_time\n",
        "        half_width = duration / 2.0\n",
        "        \n",
        "        # Slightly irregular shape\n",
        "        dip = depth * np.exp(-0.5 * (dist / (half_width * 0.5))**2)\n",
        "        # Add some asymmetry\n",
        "        if np.random.rand() > 0.5:\n",
        "            dip = dip * (1.0 + 0.2 * np.sin(2 * np.pi * dist / (duration * 0.3)))\n",
        "        \n",
        "        signal += np.where(np.abs(dist) < duration, dip, 0.0)\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def very_broad_complex_dip_signal(jd, dip_start=None, dip_duration=500.0, max_depth=1.0, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate very broad, complex dip structure with multiple minima.\n",
        "    Mimics patterns like J202402+383938 with very broad, deep, complex structures.\n",
        "    \"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.1\n",
        "    \n",
        "    dist = jd - dip_start\n",
        "    half_width = dip_duration / 2.0\n",
        "    \n",
        "    # Very broad base dip\n",
        "    base_dip = max_depth * np.exp(-0.5 * (dist / (half_width * 0.8))**2)\n",
        "    \n",
        "    # Multiple minima within the broad structure\n",
        "    n_minima = 3\n",
        "    minima_positions = np.linspace(-half_width * 0.5, half_width * 0.5, n_minima)\n",
        "    \n",
        "    for i, min_pos in enumerate(minima_positions):\n",
        "        min_depth = max_depth * (0.6 + 0.4 * (i + 1) / n_minima)\n",
        "        min_width = half_width * 0.15\n",
        "        local_dip = min_depth * np.exp(-0.5 * ((dist - min_pos) / min_width)**2)\n",
        "        base_dip = np.maximum(base_dip, local_dip)\n",
        "    \n",
        "    # Prolonged fainter state in the middle\n",
        "    flat_bottom = np.where(np.abs(dist) < half_width * 0.3, max_depth * 0.9, 0.0)\n",
        "    signal = np.maximum(base_dip, flat_bottom)\n",
        "    \n",
        "    # Only apply within the dip region\n",
        "    signal = np.where(np.abs(dist) < dip_duration, signal, 0.0)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def shallow_irregular_dips_signal(jd, n_dips=5, base_duration=80.0, base_depth=0.3, quiescent_duration=500.0):\n",
        "    \"\"\"\n",
        "    Generate multiple shallow, somewhat irregular dips throughout.\n",
        "    Mimics patterns like J184916-473251.\n",
        "    \"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    t_span = jd[-1] - jd[0] - quiescent_duration\n",
        "    \n",
        "    # Place dips more evenly throughout (after quiescent period)\n",
        "    dip_times = jd[0] + quiescent_duration + np.linspace(0.1, 0.9, n_dips) * t_span\n",
        "    \n",
        "    for dip_time in dip_times:\n",
        "        # Vary duration and depth (shallower)\n",
        "        duration = base_duration * (0.6 + 0.8 * np.random.rand())\n",
        "        depth = base_depth * (0.5 + 1.0 * np.random.rand())\n",
        "        \n",
        "        dist = jd - dip_time\n",
        "        half_width = duration / 2.0\n",
        "        \n",
        "        # Shallow, irregular dip\n",
        "        dip = depth * np.exp(-0.5 * (dist / (half_width * 0.6))**2)\n",
        "        # Add irregularity\n",
        "        dip = dip * (1.0 + 0.15 * np.sin(4 * np.pi * dist / duration))\n",
        "        \n",
        "        signal += np.where(np.abs(dist) < duration, dip, 0.0)\n",
        "    \n",
        "    # Ensure quiescent period at beginning\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    \n",
        "    return signal\n",
        "\n",
        "def asymmetric_dip_signal(jd, dip_start=None, dip_duration=80.0, depth=0.9, ingress_ratio=0.3, quiescent_duration=500.0):\n",
        "    \"\"\"Generate asymmetric dip: fast ingress, slow egress (or vice versa).\"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.3\n",
        "    dist = jd - dip_start\n",
        "    ingress_duration = dip_duration * ingress_ratio\n",
        "    egress_duration = dip_duration * (1.0 - ingress_ratio)\n",
        "    signal = np.zeros_like(jd)\n",
        "    ingress_mask = (dist >= -ingress_duration) & (dist < 0)\n",
        "    signal[ingress_mask] = depth * (1.0 + dist[ingress_mask] / ingress_duration)\n",
        "    bottom_mask = (dist >= 0) & (dist < egress_duration)\n",
        "    signal[bottom_mask] = depth\n",
        "    egress_mask = (dist >= egress_duration) & (dist < dip_duration)\n",
        "    signal[egress_mask] = depth * (1.0 - (dist[egress_mask] - egress_duration) / egress_duration)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def gradual_trend_signal(jd, trend_rate=0.0001, quiescent_duration=500.0):\n",
        "    \"\"\"Generate gradual linear trend (slow brightening or fading over years).\"\"\"\n",
        "    t = jd - jd[0] - quiescent_duration\n",
        "    t = np.maximum(t, 0.0)\n",
        "    signal = trend_rate * t\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def overlapping_dips_signal(jd, n_dips=2, base_duration=100.0, base_depth=0.7, overlap_fraction=0.3, quiescent_duration=500.0):\n",
        "    \"\"\"Generate overlapping dips (second dip starts before first fully recovers).\"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    t_span = jd[-1] - jd[0] - quiescent_duration\n",
        "    dip_times = jd[0] + quiescent_duration + np.linspace(0.2, 0.6, n_dips) * t_span\n",
        "    for i, dip_time in enumerate(dip_times):\n",
        "        duration = base_duration * (0.9 + 0.2 * np.random.rand())\n",
        "        depth = base_depth * (0.8 + 0.4 * np.random.rand())\n",
        "        dist = jd - dip_time\n",
        "        half_width = duration / 2.0\n",
        "        dip = depth * np.exp(-0.5 * (dist / (half_width * 0.5))**2)\n",
        "        signal += np.where(np.abs(dist) < duration, dip, 0.0)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def dip_with_recovery_overshoot_signal(jd, dip_start=None, dip_duration=120.0, depth=1.0, overshoot_amplitude=0.2, quiescent_duration=500.0):\n",
        "    \"\"\"Generate dip with recovery that overshoots baseline (rebrightening).\"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.3\n",
        "    dist = jd - dip_start\n",
        "    half_width = dip_duration / 2.0\n",
        "    recovery_duration = dip_duration * 0.5\n",
        "    signal = np.zeros_like(jd)\n",
        "    dip_mask = np.abs(dist) < half_width\n",
        "    signal[dip_mask] = depth * np.exp(-0.5 * (dist[dip_mask] / (half_width * 0.5))**2)\n",
        "    recovery_mask = (dist >= half_width) & (dist < half_width + recovery_duration)\n",
        "    recovery_dist = dist[recovery_mask] - half_width\n",
        "    signal[recovery_mask] = -overshoot_amplitude * np.exp(-recovery_dist / (recovery_duration * 0.3))\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def very_long_duration_dip_signal(jd, dip_start=None, dip_duration=400.0, depth=0.6, quiescent_duration=500.0):\n",
        "    \"\"\"Generate very long duration dip (approaching state change).\"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.2\n",
        "    dist = jd - dip_start\n",
        "    half_width = dip_duration / 2.0\n",
        "    signal = depth * np.exp(-0.5 * (dist / (half_width * 0.8))**2)\n",
        "    signal = np.where(np.abs(dist) < dip_duration, signal, 0.0)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def borderline_dip_signal(jd, dip_start=None, dip_duration=45.0, depth=0.4, quiescent_duration=500.0):\n",
        "    \"\"\"Generate borderline dip: exactly at 45-day threshold, shallow depth.\"\"\"\n",
        "    if dip_start is None:\n",
        "        dip_start = jd[0] + quiescent_duration + (jd[-1] - jd[0] - quiescent_duration) * 0.3\n",
        "    dist = np.abs(jd - dip_start)\n",
        "    half_width = dip_duration / 2.0\n",
        "    signal = depth * np.exp(-0.5 * (dist / (half_width * 0.5))**2)\n",
        "    signal = np.where(dist < dip_duration, signal, 0.0)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def long_period_eclipsing_binary_signal(jd, period=200.0, depth=0.8, quiescent_duration=500.0):\n",
        "    \"\"\"Generate long-period eclipsing binary (might look like single dip if period >> observation span).\"\"\"\n",
        "    t = jd - jd[0] - quiescent_duration\n",
        "    t = np.maximum(t, 0.0)\n",
        "    phase = (t % period) / period\n",
        "    eclipse_width = 0.05\n",
        "    signal = np.where((phase < eclipse_width) | (phase > 1.0 - eclipse_width),\n",
        "                     depth * np.exp(-((np.minimum(phase, 1.0 - phase) / eclipse_width)**2)),\n",
        "                     0.0)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def stochastic_variability_signal(jd, timescale=50.0, amplitude=0.3, quiescent_duration=500.0):\n",
        "    \"\"\"Generate stochastic variability (like blazars/AGN): red noise, no clear pattern.\"\"\"\n",
        "    signal = np.zeros_like(jd)\n",
        "    n = len(jd)\n",
        "    active_start_idx = np.searchsorted(jd, jd[0] + quiescent_duration)\n",
        "    if active_start_idx < n:\n",
        "        dt = np.diff(jd)\n",
        "        signal[active_start_idx] = np.random.randn() * amplitude * 0.5\n",
        "        for i in range(active_start_idx + 1, n):\n",
        "            signal[i] = signal[i-1] * np.exp(-dt[i-1] / timescale) + \\\n",
        "                        np.random.randn() * amplitude * np.sqrt(1.0 - np.exp(-2 * dt[i-1] / timescale))\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def dip_near_quiescent_boundary_signal(jd, dip_start_offset=10.0, dip_duration=60.0, depth=0.8, quiescent_duration=500.0):\n",
        "    \"\"\"Generate dip that starts very close to quiescent period boundary.\"\"\"\n",
        "    dip_start = jd[0] + quiescent_duration + dip_start_offset\n",
        "    dist = np.abs(jd - dip_start)\n",
        "    half_width = dip_duration / 2.0\n",
        "    signal = depth * np.exp(-0.5 * (dist / (half_width * 0.5))**2)\n",
        "    signal = np.where(dist < dip_duration, signal, 0.0)\n",
        "    quiescent_mask = jd < (jd[0] + quiescent_duration)\n",
        "    signal[quiescent_mask] = 0.0\n",
        "    return signal\n",
        "\n",
        "def test_injection(gp_kwargs=None, out_dir=None):\n",
        "    \"\"\"\n",
        "    Run injection tests: big dippers vs non-dippers.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    gp_kwargs : dict\n",
        "        GP hyperparameters\n",
        "    out_dir : Path\n",
        "        Output directory for plots\n",
        "    \"\"\"\n",
        "    # Use _gp_kwargs (S0, w0, q, jitter) from earlier cells - ENFORCED (same as other cells)\n",
        "    if gp_kwargs is None:\n",
        "        if \"_gp_kwargs\" in globals():\n",
        "            gp_kwargs = globals()[\"_gp_kwargs\"].copy()\n",
        "            print(f\"\u2713 Using _gp_kwargs from earlier cell: {gp_kwargs}\")\n",
        "        elif \"gp_kwargs\" in globals():\n",
        "            gp_kwargs = globals()[\"gp_kwargs\"].copy()\n",
        "            print(f\"\u2713 Using gp_kwargs from earlier cell: {gp_kwargs}\")\n",
        "        else:\n",
        "            gp_kwargs = {\"S0\": 0.0005, \"w0\": 0.0031415926535897933, \"q\": 0.7, \"jitter\": 0.006}\n",
        "            print(f\"\u26a0 Using default gp_kwargs: {gp_kwargs}\")\n",
        "    else:\n",
        "        print(f\"\u2713 Using provided gp_kwargs: {gp_kwargs}\")\n",
        "    \n",
        "    # Prepare masked GP kwargs (convert q->Q, add masking params)\n",
        "    if \"gp_params\" in globals():\n",
        "        gp_masked_kwargs = globals()[\"gp_params\"].copy()\n",
        "        # Ensure we use _gp_kwargs for kernel params\n",
        "        if \"_gp_kwargs\" in globals():\n",
        "            gp_masked_kwargs.update(globals()[\"_gp_kwargs\"])\n",
        "            if \"q\" in gp_masked_kwargs:\n",
        "                gp_masked_kwargs[\"Q\"] = gp_masked_kwargs.pop(\"q\")\n",
        "        print(f\"\u2713 Using gp_params + _gp_kwargs for masked GP: {gp_masked_kwargs}\")\n",
        "    else:\n",
        "        # Build from _gp_kwargs\n",
        "        gp_masked_kwargs = gp_kwargs.copy()\n",
        "        if \"q\" in gp_masked_kwargs:\n",
        "            gp_masked_kwargs[\"Q\"] = gp_masked_kwargs.pop(\"q\")\n",
        "        gp_masked_kwargs.setdefault(\"dip_sigma_thresh\", -1.0)\n",
        "        gp_masked_kwargs.setdefault(\"pad_days\", 100.0)\n",
        "        print(f\"\u2713 Using _gp_kwargs + defaults for masked GP: {gp_masked_kwargs}\")\n",
        "    \n",
        "    if out_dir is None:\n",
        "        out_dir = Path(\"../../lc_plots/injection_tests\")\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"GP kwargs: {gp_kwargs}\")\n",
        "    print(f\"Output directory: {out_dir.resolve()}\\n\")\n",
        "    \n",
        "    # Test cases: non-periodic big dippers (single events, 45+ days duration)\n",
        "    # Test cases: non-periodic big dippers (single events, 45+ days duration) + false positives\n",
        "    test_cases = [\n",
        "        # ===== TARGET SIGNALS (what we want to detect) =====\n",
        "        # Simple big dippers\n",
        "        {\n",
        "            \"name\": \"Big Dipper (single, 60d)\",\n",
        "            \"description\": \"Single 0.8 mag dip, 60 day duration\",\n",
        "            \"inject\": lambda jd: single_big_dipper_signal(jd, dip_duration=60.0, depth=0.8, shape=\"gaussian\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Big Dipper (single, very deep)\",\n",
        "            \"description\": \"Single 1.2 mag dip, 50 day duration\",\n",
        "            \"inject\": lambda jd: single_big_dipper_signal(jd, dip_duration=50.0, depth=1.2, shape=\"gaussian\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Big Dipper (single, long duration)\",\n",
        "            \"description\": \"Single 0.7 mag dip, 90 day duration\",\n",
        "            \"inject\": lambda jd: single_big_dipper_signal(jd, dip_duration=90.0, depth=0.7, shape=\"gaussian\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Big Dipper (flat-bottomed)\",\n",
        "            \"description\": \"Single 0.9 mag dip, 55 day duration, flat bottom\",\n",
        "            \"inject\": lambda jd: single_big_dipper_signal(jd, dip_duration=55.0, depth=0.9, shape=\"box\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        # Real dipper patterns (from observed light curves)\n",
        "        {\n",
        "            \"name\": \"Deep Complex Dip\",\n",
        "            \"description\": \"Very deep, complex dip with multiple minima (J070519-like)\",\n",
        "            \"inject\": lambda jd: deep_complex_dip_signal(jd, dip_duration=200.0, max_depth=1.5),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Broad U-Shaped Dip\",\n",
        "            \"description\": \"Broad, deep U-shaped dip (J081523-like)\",\n",
        "            \"inject\": lambda jd: broad_u_shaped_dip_signal(jd, dip_duration=300.0, depth=1.2, shape=\"U\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Broad V-Shaped Dip\",\n",
        "            \"description\": \"Broad, deep V-shaped dip (J183153-like)\",\n",
        "            \"inject\": lambda jd: broad_u_shaped_dip_signal(jd, dip_duration=250.0, depth=1.0, shape=\"V\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Sudden State Change\",\n",
        "            \"description\": \"Sudden jump to fainter state (J085816-like)\",\n",
        "            \"inject\": lambda jd: sudden_state_change_signal(jd, depth=0.8),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Multiple Irregular Dips\",\n",
        "            \"description\": \"Multiple somewhat irregular dips (J181707-like)\",\n",
        "            \"inject\": lambda jd: multiple_irregular_dips_signal(jd, n_dips=3, base_duration=150.0, base_depth=0.8),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Very Broad Complex Dip\",\n",
        "            \"description\": \"Very broad, complex structure with multiple minima (J202402-like)\",\n",
        "            \"inject\": lambda jd: very_broad_complex_dip_signal(jd, dip_duration=500.0, max_depth=1.0),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Shallow Irregular Dips\",\n",
        "            \"description\": \"Multiple shallow, irregular dips (J184916-like)\",\n",
        "            \"inject\": lambda jd: shallow_irregular_dips_signal(jd, n_dips=5, base_duration=80.0, base_depth=0.3),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        # ===== FALSE POSITIVES (what we want to avoid detecting) =====\n",
        "        {\n",
        "            \"name\": \"Camera Offset\",\n",
        "            \"description\": \"Systematic offsets per camera (horizontal bands)\",\n",
        "            \"inject\": lambda jd, cameras: camera_offset_signal(jd, cameras, offset_magnitude=0.25),\n",
        "            \"cameras\": [\"A\", \"B\", \"C\", \"D\"],\n",
        "            \"needs_cameras\": True,  # Flag to pass cameras to inject function\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Bad Point Cluster\",\n",
        "            \"description\": \"Localized cluster of bad/faint points\",\n",
        "            \"inject\": lambda jd: bad_point_cluster_signal(jd, cluster_offset=0.5, cluster_width=25.0),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Semi-Regular Variable\",\n",
        "            \"description\": \"Oscillating with varying period/amplitude\",\n",
        "            \"inject\": lambda jd: semi_regular_variable_signal(jd, base_period=120.0, amplitude=0.2),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Contact Binary\",\n",
        "            \"description\": \"Periodic double-peaked (P=0.5 days)\",\n",
        "            \"inject\": lambda jd: contact_binary_signal(jd, period=0.5, amplitude=0.25),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"T Tauri-like\",\n",
        "            \"description\": \"Large irregular scatter, no clear pattern\",\n",
        "            \"inject\": lambda jd: ttauri_like_signal(jd, scatter_amplitude=0.8),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"RCB-like\",\n",
        "            \"description\": \"Sudden deep dimmings with gradual recovery\",\n",
        "            \"inject\": lambda jd: rcb_like_signal(jd, n_events=3, event_depth=0.9),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        # ===== EDGE CASES & CHALLENGING PATTERNS =====\n",
        "        {\n",
        "            \"name\": \"Asymmetric Dip (fast ingress)\",\n",
        "            \"description\": \"Fast ingress, slow egress (30/70 split)\",\n",
        "            \"inject\": lambda jd: asymmetric_dip_signal(jd, dip_duration=80.0, depth=0.9, ingress_ratio=0.3),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Asymmetric Dip (slow ingress)\",\n",
        "            \"description\": \"Slow ingress, fast egress (70/30 split)\",\n",
        "            \"inject\": lambda jd: asymmetric_dip_signal(jd, dip_duration=80.0, depth=0.9, ingress_ratio=0.7),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Overlapping Dips\",\n",
        "            \"description\": \"Two overlapping dips (second starts before first recovers)\",\n",
        "            \"inject\": lambda jd: overlapping_dips_signal(jd, n_dips=2, base_duration=100.0, base_depth=0.7),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Dip with Recovery Overshoot\",\n",
        "            \"description\": \"Dip followed by rebrightening above baseline\",\n",
        "            \"inject\": lambda jd: dip_with_recovery_overshoot_signal(jd, dip_duration=120.0, depth=1.0, overshoot_amplitude=0.2),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Very Long Duration Dip\",\n",
        "            \"description\": \"400-day dip (borderline state change)\",\n",
        "            \"inject\": lambda jd: very_long_duration_dip_signal(jd, dip_duration=400.0, depth=0.6),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Borderline Dip (45d, shallow)\",\n",
        "            \"description\": \"Exactly 45 days, shallow (0.4 mag) - detection limit test\",\n",
        "            \"inject\": lambda jd: borderline_dip_signal(jd, dip_duration=45.0, depth=0.4),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Dip Near Quiescent Boundary\",\n",
        "            \"description\": \"Dip starts 10 days after quiescent period (minimal baseline)\",\n",
        "            \"inject\": lambda jd: dip_near_quiescent_boundary_signal(jd, dip_start_offset=10.0, dip_duration=60.0, depth=0.8),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Gradual Linear Trend\",\n",
        "            \"description\": \"Slow brightening over time (0.0001 mag/day)\",\n",
        "            \"inject\": lambda jd: gradual_trend_signal(jd, trend_rate=0.0001),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Long-Period Eclipsing Binary\",\n",
        "            \"description\": \"P=200d eclipsing binary (might look like single dip)\",\n",
        "            \"inject\": lambda jd: long_period_eclipsing_binary_signal(jd, period=200.0, depth=0.8),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Stochastic Variability\",\n",
        "            \"description\": \"Red noise variability (blazar/AGN-like)\",\n",
        "            \"inject\": lambda jd: stochastic_variability_signal(jd, timescale=50.0, amplitude=0.3),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        # ===== CONTROL CASES =====\n",
        "        {\n",
        "            \"name\": \"No signal (pure noise)\",\n",
        "            \"description\": \"Baseline + noise only\",\n",
        "            \"inject\": None,\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Shallow variability\",\n",
        "            \"description\": \"0.05 mag sinusoidal variation (not a dipper)\",\n",
        "            \"inject\": lambda jd: shallow_variability_signal(jd, amplitude=0.05, timescale=20.0),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Short dip (reject)\",\n",
        "            \"description\": \"Single 0.3 mag dip, 20 day duration (too short)\",\n",
        "            \"inject\": lambda jd: single_big_dipper_signal(jd, dip_duration=20.0, depth=0.3, shape=\"gaussian\"),\n",
        "            \"cameras\": [\"A\", \"B\"],\n",
        "        },\n",
        "    ]\n",
        "    \n",
        "    n_cases = len(test_cases)\n",
        "    fig, axes = plt.subplots(n_cases, 2, figsize=(14, 3 * n_cases), sharex='col')\n",
        "    fig.suptitle(\"Injection Tests: GP (SHO) vs GP Masked - Targets vs False Positives\", \n",
        "                 fontsize=14, y=0.995)\n",
        "    \n",
        "    if n_cases == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for case_idx, case in enumerate(test_cases):\n",
        "        # Generate synthetic light curve spanning 3000 days\n",
        "        cadence = 0.5  # days between observations\n",
        "        n_points = int(3000 / cadence)  # 6000 points for 3000 days\n",
        "        \n",
        "        # Check if inject function needs cameras argument\n",
        "        if case.get(\"needs_cameras\", False):\n",
        "            # Generate cameras first for camera_offset_signal\n",
        "            # Create the exact jd array that will be used\n",
        "            jd_temp = 2458000 + np.arange(n_points) * cadence\n",
        "            cameras_list = []\n",
        "            for i in range(n_points):\n",
        "                cameras_list.append(case[\"cameras\"][i % len(case[\"cameras\"])])\n",
        "            \n",
        "            inject_func = case[\"inject\"]\n",
        "            signal = inject_func(jd_temp, cameras_list)\n",
        "            \n",
        "            # Now generate LC with this signal (signal must match jd indices)\n",
        "            df_synth = generate_synthetic_lc(\n",
        "                n_points=n_points,\n",
        "                jd_start=2458000,\n",
        "                cadence=cadence,\n",
        "                baseline_mag=15.0,\n",
        "                noise_level=0.01,\n",
        "                inject_signal=lambda jd: signal,  # Use pre-computed signal (indices match)\n",
        "                cameras=case[\"cameras\"],\n",
        "            )\n",
        "        else:\n",
        "            df_synth = generate_synthetic_lc(\n",
        "                n_points=n_points,\n",
        "                jd_start=2458000,\n",
        "                cadence=cadence,\n",
        "                baseline_mag=15.0,\n",
        "                noise_level=0.01,\n",
        "                inject_signal=case[\"inject\"],\n",
        "                cameras=case[\"cameras\"],\n",
        "            )\n",
        "        \n",
        "        # Run both GP baselines\n",
        "        try:\n",
        "            result_gp = per_camera_gp_baseline(df_synth.copy(), **gp_kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0\ufe0f  {case['name']} GP baseline failed: {e}\")\n",
        "            result_gp = None\n",
        "        \n",
        "        try:\n",
        "            result_masked = per_camera_gp_baseline_masked(df_synth.copy(), **gp_masked_kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0\ufe0f  {case['name']} GP masked baseline failed: {e}\")\n",
        "            result_masked = None\n",
        "        \n",
        "        if result_gp is None and result_masked is None:\n",
        "            continue\n",
        "        \n",
        "        # Use GP result for jd/mag (they should be the same)\n",
        "        if result_gp is not None:\n",
        "            result = result_gp\n",
        "        else:\n",
        "            result = result_masked\n",
        "        \n",
        "        jd = result[\"JD\"].values - 2458000\n",
        "        mag = result[\"mag\"].values\n",
        "        \n",
        "        # Left plot: Data + Both Baselines\n",
        "        ax_left = axes[case_idx, 0]\n",
        "        ax_left.scatter(jd, mag, s=2, alpha=0.3, c='gray', zorder=1, label='Data')\n",
        "        \n",
        "        # Plot GP baseline (regular)\n",
        "        if result_gp is not None:\n",
        "            baseline_gp = result_gp[\"baseline\"].values\n",
        "            cams = sorted(result_gp[\"camera#\"].dropna().unique())\n",
        "            for i_cam, cam in enumerate(cams):\n",
        "                cam_mask = result_gp[\"camera#\"] == cam\n",
        "                cam_jd = jd[cam_mask]\n",
        "                cam_baseline = baseline_gp[cam_mask]\n",
        "                sort_idx = np.argsort(cam_jd)\n",
        "                ax_left.plot(cam_jd[sort_idx], cam_baseline[sort_idx], \n",
        "                            '-', color='blue', lw=1.5, alpha=0.8, zorder=2, \n",
        "                            label='GP (SHO)' if i_cam == 0 else None)\n",
        "        \n",
        "        # Plot GP baseline (masked)\n",
        "        if result_masked is not None:\n",
        "            baseline_masked = result_masked[\"baseline\"].values\n",
        "            cams = sorted(result_masked[\"camera#\"].dropna().unique())\n",
        "            for i_cam, cam in enumerate(cams):\n",
        "                cam_mask = result_masked[\"camera#\"] == cam\n",
        "                cam_jd = jd[cam_mask]\n",
        "                cam_baseline = baseline_masked[cam_mask]\n",
        "                sort_idx = np.argsort(cam_jd)\n",
        "                ax_left.plot(cam_jd[sort_idx], cam_baseline[sort_idx], \n",
        "                            '--', color='red', lw=1.5, alpha=0.8, zorder=2,\n",
        "                            label='GP Masked' if i_cam == 0 else None)\n",
        "        \n",
        "        ax_left.invert_yaxis()\n",
        "        ax_left.set_ylabel(\"mag\", fontsize=9)\n",
        "        ax_left.set_title(f\"{case['name']}\\n{case['description']}\", fontsize=9, fontweight='bold')\n",
        "        ax_left.grid(True, alpha=0.3)\n",
        "        if case_idx == 0:\n",
        "            ax_left.legend(loc='best', fontsize=7)\n",
        "        \n",
        "        # Right plot: Residuals (both methods)\n",
        "        ax_right = axes[case_idx, 1]\n",
        "        \n",
        "        # Plot GP residuals\n",
        "        if result_gp is not None:\n",
        "            resid_gp = result_gp[\"resid\"].values\n",
        "            ax_right.scatter(jd, resid_gp, s=2, alpha=0.4, c='blue', marker='o', \n",
        "                           zorder=1, label='GP (SHO)')\n",
        "        \n",
        "        # Plot GP masked residuals\n",
        "        if result_masked is not None:\n",
        "            resid_masked = result_masked[\"resid\"].values\n",
        "            ax_right.scatter(jd, resid_masked, s=2, alpha=0.4, c='red', marker='x', \n",
        "                           zorder=1, label='GP Masked')\n",
        "        \n",
        "        ax_right.axhline(0, color='k', linestyle='--', alpha=0.5, linewidth=0.8)\n",
        "        ax_right.axhline(0.3, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
        "        ax_right.axhline(-0.3, color='gray', linestyle=':', alpha=0.3, linewidth=0.5)\n",
        "        ax_right.invert_yaxis()\n",
        "        ax_right.set_ylabel(\"Residual\", fontsize=9)\n",
        "        ax_right.set_title(\"Residuals\", fontsize=9)\n",
        "        ax_right.grid(True, alpha=0.3)\n",
        "        if case_idx == 0:\n",
        "            ax_right.legend(loc='best', fontsize=7)\n",
        "        \n",
        "        # Statistics for both methods\n",
        "        stats_lines = []\n",
        "        if result_gp is not None:\n",
        "            sigma_resid_gp = result_gp[\"sigma_resid\"].values\n",
        "            resid_gp = result_gp[\"resid\"].values\n",
        "            n_dips_gp = (sigma_resid_gp < -3).sum()\n",
        "            mad_gp = 1.4826 * np.median(np.abs(resid_gp - np.median(resid_gp)))\n",
        "            max_dip_gp = np.nanmax(resid_gp) if len(resid_gp) > 0 else np.nan\n",
        "            stats_lines.append(f\"GP: {n_dips_gp} dips, MAD={mad_gp:.4f}, max={max_dip_gp:.3f}\")\n",
        "        \n",
        "        if result_masked is not None:\n",
        "            sigma_resid_masked = result_masked[\"sigma_resid\"].values\n",
        "            resid_masked = result_masked[\"resid\"].values\n",
        "            n_dips_masked = (sigma_resid_masked < -3).sum()\n",
        "            mad_masked = 1.4826 * np.median(np.abs(resid_masked - np.median(resid_masked)))\n",
        "            max_dip_masked = np.nanmax(resid_masked) if len(resid_masked) > 0 else np.nan\n",
        "            stats_lines.append(f\"Masked: {n_dips_masked} dips, MAD={mad_masked:.4f}, max={max_dip_masked:.3f}\")\n",
        "        \n",
        "        stats_text = \"\\n\".join(stats_lines)\n",
        "        ax_right.text(0.02, 0.98, stats_text, transform=ax_right.transAxes, \n",
        "                     fontsize=7, verticalalignment='top',\n",
        "                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "        \n",
        "        if case_idx == n_cases - 1:\n",
        "            ax_left.set_xlabel(\"JD - 2458000\", fontsize=9)\n",
        "            ax_right.set_xlabel(\"JD - 2458000\", fontsize=9)\n",
        "        \n",
        "        print(f\"{case['name']}: \" + \" | \".join(stats_lines))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save to PDF\n",
        "    out_path = out_dir / \"injection_tests_gp_baseline.pdf\"\n",
        "    fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"\\n\u2713 Saved injection test plot to: {out_path.resolve()}\")\n",
        "    \n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Run injection tests\n",
        "print(\"=\"*80)\n",
        "print(\"INJECTION TESTS: Testing GP Baseline on Synthetic Signals\")\n",
        "print(\"=\"*80)\n",
        "print(\"Targets: Single, non-periodic, non-repeating deep dips with duration >= 45 days\")\n",
        "print(\"False Positives: Camera offsets, bad clusters, periodic variables, etc.\")\n",
        "print(\"Using same _gp_kwargs as other cells (S0, w0, q, jitter)\")\n",
        "print(\"=\"*80)\n",
        "test_injection()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "asassn-variability",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}